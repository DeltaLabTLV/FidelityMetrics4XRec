{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18831b05",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160299a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import logging\n",
    "import ipynb\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56467a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a2c01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"MLP\" ## Can be MLP, VAE, NCF\n",
    "\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd()).parent\n",
    "files_path = Path(export_dir, DP_DIR)\n",
    "checkpoints_path = Path(export_dir, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12301f4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19a6b87",
   "metadata": {},
   "source": [
    "## Data imports and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1b88a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "static_test_data = pd.read_csv(Path(files_path,f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "    \n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29108508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in range(static_test_data.shape[0]):\n",
    "    static_test_data.iloc[row, static_test_data.iloc[row,-2]]=0\n",
    "test_array = static_test_data.iloc[:,:-2].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0abdd7e8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2db85e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Recommenders Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b959e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abc79dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Define the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f96fd51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_dict = {'device':device,\n",
    "          'num_items': num_items,\n",
    "           'num_features': num_items, \n",
    "           'demographic':False,\n",
    "          'pop_array':pop_array,\n",
    "          'all_items_tensor':all_items_tensor,\n",
    "          'static_test_data':static_test_data,\n",
    "          'items_array':items_array,\n",
    "          'output_type':output_type,\n",
    "          'recommender_name':recommender_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771d610",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b818020",
   "metadata": {},
   "source": [
    "## MLP Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ade5586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses_dict = {}\n",
    "test_losses_dict = {}\n",
    "HR10_dict = {}\n",
    "\n",
    "def MLP_objective(trial):\n",
    "    \n",
    "    lr = trial.suggest_float('learning_rate', 0.001, 0.01)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [256, 512, 1024])\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [64, 128, 256, 512])\n",
    "    beta = trial.suggest_float('beta', 0, 4)\n",
    "    epochs = 10\n",
    "    model = MLP(hidden_dim, **kw_dict)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    hr10 = []\n",
    "    print(f'======================== new run - {recommender_name} ========================')\n",
    "    logger.info(f'======================== new run - {recommender_name} ========================')\n",
    "    \n",
    "    num_training = train_data.shape[0]\n",
    "    num_batches = int(np.ceil(num_training / batch_size))\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_matrix = sample_indices(train_data.copy(), **kw_dict)\n",
    "        perm = np.random.permutation(num_training)\n",
    "        loss = []\n",
    "        train_pos_loss=[]\n",
    "        train_neg_loss=[]\n",
    "        if epoch!=0 and epoch%10 == 0:\n",
    "            lr = 0.1*lr\n",
    "            optimizer.lr = lr\n",
    "        \n",
    "        for b in range(num_batches):\n",
    "            optimizer.zero_grad()\n",
    "            if (b + 1) * batch_size >= num_training:\n",
    "                batch_idx = perm[b * batch_size:]\n",
    "            else:\n",
    "                batch_idx = perm[b * batch_size: (b + 1) * batch_size]    \n",
    "            batch_matrix = torch.FloatTensor(train_matrix[batch_idx,:-2]).to(device)\n",
    "\n",
    "            batch_pos_idx = train_matrix[batch_idx,-2]\n",
    "            batch_neg_idx = train_matrix[batch_idx,-1]\n",
    "            \n",
    "            batch_pos_items = torch.Tensor(items_array[batch_pos_idx]).to(device)\n",
    "            batch_neg_items = torch.Tensor(items_array[batch_neg_idx]).to(device)\n",
    "            \n",
    "            pos_output = torch.diagonal(model(batch_matrix, batch_pos_items))\n",
    "            neg_output = torch.diagonal(model(batch_matrix, batch_neg_items))\n",
    "            \n",
    "            pos_loss = torch.mean((torch.ones_like(pos_output)-pos_output)**2)\n",
    "            neg_loss = torch.mean((neg_output)**2)\n",
    "            \n",
    "            batch_loss = pos_loss + beta*neg_loss\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss.append(batch_loss.item())\n",
    "            train_pos_loss.append(pos_loss.item())\n",
    "            train_neg_loss.append(neg_loss.item())\n",
    "            \n",
    "        print(f'train pos_loss = {np.mean(train_pos_loss)}, neg_loss = {np.mean(train_neg_loss)}')    \n",
    "        train_losses.append(np.mean(loss))\n",
    "        torch.save(model.state_dict(), Path(checkpoints_path, f'MLP_{data_name}_{round(lr,4)}_{batch_size}_{trial.number}_{epoch}.pt'))\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        test_matrix = np.array(static_test_data)\n",
    "        test_tensor = torch.Tensor(test_matrix[:,:-2]).to(device)\n",
    "        \n",
    "        test_pos = test_matrix[:,-2]\n",
    "        test_neg = test_matrix[:,-1]\n",
    "        \n",
    "        row_indices = np.arange(test_matrix.shape[0])\n",
    "        test_tensor[row_indices,test_pos] = 0\n",
    "        \n",
    "        pos_items = torch.Tensor(items_array[test_pos]).to(device)\n",
    "        neg_items = torch.Tensor(items_array[test_neg]).to(device)\n",
    "        \n",
    "        pos_output = torch.diagonal(model(test_tensor, pos_items).to(device))\n",
    "        neg_output = torch.diagonal(model(test_tensor, neg_items).to(device))\n",
    "        \n",
    "        pos_loss = torch.mean((torch.ones_like(pos_output)-pos_output)**2)\n",
    "        neg_loss = torch.mean((neg_output)**2)\n",
    "        print(f'test pos_loss = {pos_loss}, neg_loss = {neg_loss}')\n",
    "        \n",
    "        hit_rate_at_10, hit_rate_at_50, hit_rate_at_100, MRR, MPR = recommender_evaluations(model, **kw_dict)\n",
    "        hr10.append(hit_rate_at_10)\n",
    "        print(hit_rate_at_10, hit_rate_at_50, hit_rate_at_100, MRR, MPR)\n",
    "        \n",
    "        test_losses.append(-hit_rate_at_10)\n",
    "        if epoch>5:\n",
    "            if test_losses[-2]<=test_losses[-1] and test_losses[-3]<=test_losses[-2] and test_losses[-4]<=test_losses[-3]:\n",
    "                logger.info(f'Early stop at trial with batch size = {batch_size} and lr = {lr}. Best results at epoch {np.argmin(test_losses)} with value {np.min(test_losses)}')\n",
    "                train_losses_dict[trial.number] = train_losses\n",
    "                test_losses_dict[trial.number] = test_losses\n",
    "                HR10_dict[trial.number] = hr10\n",
    "                return max(hr10)\n",
    "            \n",
    "    logger.info(f'Stop at trial with batch size = {batch_size} and lr = {lr}. Best results at epoch {np.argmin(test_losses)} with value {np.min(test_losses)}')\n",
    "    train_losses_dict[trial.number] = train_losses\n",
    "    test_losses_dict[trial.number] = test_losses\n",
    "    HR10_dict[trial.number] = hr10\n",
    "    return max(hr10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc5616",
   "metadata": {},
   "source": [
    "## VAE Train function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826593a-e763-4776-90a0-94be8c4d5b9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Define the configs (they are defined once again inside the load recommender function in the \"help funcion\" notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143f8609-1f73-47db-8923-763274c726a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_config= {\n",
    "\"enc_dims\": [512,128],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}\n",
    "\n",
    "\n",
    "Pinterest_VAE_config= {\n",
    "\"enc_dims\": [256,64],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d9369-4c29-4ea5-876f-d770dfbaffaa",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95bb9edc-c2d8-4d18-b191-dd08e6a269a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_vae(n_splits=5):\n",
    "    # Combine data for splitting\n",
    "    all_data = pd.concat([train_data, test_data])\n",
    "    \n",
    "    # Добавляем столбцы pos и neg, если их нет\n",
    "    if all_data.shape[1] == num_items:\n",
    "        # Для каждого пользователя находим один случайный положительный и отрицательный предмет\n",
    "        pos_items = []\n",
    "        neg_items = []\n",
    "        for _, user_data in all_data.iterrows():\n",
    "            # Находим индексы положительных и отрицательных взаимодействий\n",
    "            pos_indices = np.where(user_data > 0)[0]\n",
    "            neg_indices = np.where(user_data == 0)[0]\n",
    "            \n",
    "            # Выбираем случайный положительный и отрицательный предмет\n",
    "            if len(pos_indices) > 0:\n",
    "                pos_items.append(np.random.choice(pos_indices))\n",
    "            else:\n",
    "                pos_items.append(0)  # fallback\n",
    "                \n",
    "            if len(neg_indices) > 0:\n",
    "                neg_items.append(np.random.choice(neg_indices))\n",
    "            else:\n",
    "                neg_items.append(0)  # fallback\n",
    "        \n",
    "        all_data['pos'] = pos_items\n",
    "        all_data['neg'] = neg_items\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(all_data)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        # Split data\n",
    "        fold_train = all_data.iloc[train_idx]\n",
    "        fold_test = all_data.iloc[test_idx]\n",
    "        \n",
    "        # Создаем копию kw_dict и обновляем static_test_data\n",
    "        fold_kw_dict = kw_dict.copy()\n",
    "        fold_kw_dict['static_test_data'] = fold_test\n",
    "        \n",
    "        # Initialize and train model\n",
    "        model = VAE(VAE_config, **kw_dict)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        print(f\"Fold shapes - Train: {fold_train.shape}, Test: {fold_test.shape}\")\n",
    "        \n",
    "        # Training loop\n",
    "        best_hr10 = 0\n",
    "        for epoch in range(50):\n",
    "            # Тренируем только на данных взаимодействий (без pos/neg столбцов)\n",
    "            loss = model.train_one_epoch(fold_train.iloc[:, :num_items].to_numpy(), \n",
    "                                       optimizer, batch_size=128)\n",
    "            \n",
    "            # Evaluation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                hit_rate_at_10, _, _, _, _ = recommender_evaluations(model, **fold_kw_dict)\n",
    "                \n",
    "                if hit_rate_at_10 > best_hr10:\n",
    "                    best_hr10 = hit_rate_at_10\n",
    "        \n",
    "        fold_results.append(best_hr10)\n",
    "        print(f\"Fold {fold + 1} best HR@10: {best_hr10:.4f}\")\n",
    "    \n",
    "    print(\"\\nCross-validation results:\")\n",
    "    print(f\"Mean HR@10: {np.mean(fold_results):.4f} ± {np.std(fold_results):.4f}\")\n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a68648a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses_dict = {}\n",
    "test_losses_dict = {}\n",
    "HR10_dict = {}\n",
    "\n",
    "def VAE_objective(trial):\n",
    "    lr = trial.suggest_float('learning_rate', 0.001, 0.01)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64,128,256])\n",
    "    epochs = 50  # Increased number of epochs to find optimal value\n",
    "    \n",
    "    if data_name == \"Pinterest\":\n",
    "        model = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "    else:\n",
    "        model = VAE(VAE_config, **kw_dict)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    hr10 = []\n",
    "    best_hr10 = 0\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    print('======================== new run ========================')\n",
    "    logger.info('======================== new run ========================')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Learning rate decay\n",
    "        if epoch!=0 and epoch%10 == 0:\n",
    "            lr = 0.1*lr\n",
    "            optimizer.lr = lr\n",
    "            \n",
    "        # Training step\n",
    "        loss = model.train_one_epoch(train_array, optimizer, batch_size)\n",
    "        train_losses.append(loss)\n",
    "        \n",
    "        # Save checkpoint at each epoch\n",
    "        torch.save(model.state_dict(), \n",
    "                  Path(checkpoints_path, f'VAE_{data_name}_{trial.number}_{epoch}_{round(lr,4)}_{batch_size}.pt'))\n",
    "\n",
    "        # Evaluation step\n",
    "        model.eval()\n",
    "        test_matrix = static_test_data.to_numpy()\n",
    "        test_tensor = torch.Tensor(test_matrix[:,:-2]).to(device)\n",
    "        test_pos = test_array[:,-2]\n",
    "        test_neg = test_array[:,-1]\n",
    "        row_indices = np.arange(test_matrix.shape[0])\n",
    "        test_tensor[row_indices,test_pos] = 0\n",
    "        output = model(test_tensor).to(device)\n",
    "        pos_loss = -output[row_indices,test_pos].mean()\n",
    "        neg_loss = output[row_indices,test_neg].mean()\n",
    "        print(f'Epoch {epoch} - pos_loss = {pos_loss}, neg_loss = {neg_loss}')\n",
    "        \n",
    "        # Calculate metrics\n",
    "        hit_rate_at_10, hit_rate_at_50, hit_rate_at_100, MRR, MPR = recommender_evaluations(model, **kw_dict)\n",
    "        hr10.append(hit_rate_at_10)\n",
    "        print(f'Epoch {epoch} - HR@10: {hit_rate_at_10:.4f}, HR@50: {hit_rate_at_50:.4f}, '\n",
    "              f'HR@100: {hit_rate_at_100:.4f}, MRR: {MRR:.4f}, MPR: {MPR:.4f}')\n",
    "        \n",
    "        test_losses.append(pos_loss.item())\n",
    "        \n",
    "        # Track improvements in HR@10\n",
    "        if hit_rate_at_10 > best_hr10:\n",
    "            best_hr10 = hit_rate_at_10\n",
    "            best_epoch = epoch\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the best model separately\n",
    "            torch.save(model.state_dict(), \n",
    "                      Path(checkpoints_path, f'VAE_{data_name}_{trial.number}_best_{round(lr,4)}_{batch_size}.pt'))\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Early stopping if no improvement for 10 epochs\n",
    "        if epochs_without_improvement >= 10:\n",
    "            logger.info(f'Early stop at epoch {epoch}. Best HR@10: {best_hr10:.4f} at epoch {best_epoch}')\n",
    "            break\n",
    "    \n",
    "    logger.info(f'Trial {trial.number} finished. Best HR@10: {best_hr10:.4f} at epoch {best_epoch}')\n",
    "    train_losses_dict[trial.number] = train_losses\n",
    "    test_losses_dict[trial.number] = test_losses\n",
    "    HR10_dict[trial.number] = hr10\n",
    "    \n",
    "    return best_hr10\n",
    "\n",
    "def analyze_checkpoints(best_trial_num):\n",
    "    \"\"\"\n",
    "    Analyzes the best trial to determine gold, silver, and bronze checkpoints\n",
    "    based on model performance at different epochs.\n",
    "    \n",
    "    Args:\n",
    "        best_trial_num: The number of the best trial from optimization\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Epochs for gold, silver, and bronze checkpoints\n",
    "    \"\"\"\n",
    "    hr10_values = HR10_dict[best_trial_num]\n",
    "    max_hr10 = max(hr10_values)\n",
    "    best_epoch = hr10_values.index(max_hr10)\n",
    "    \n",
    "    # Gold - best performing epoch\n",
    "    gold_hr10 = max_hr10\n",
    "    gold_epoch = best_epoch\n",
    "    \n",
    "    # Silver - ~60% of maximum performance\n",
    "    silver_target = 0.6 * max_hr10\n",
    "    silver_epoch = next(i for i, x in enumerate(hr10_values) \n",
    "                       if x >= silver_target)\n",
    "    silver_hr10 = hr10_values[silver_epoch]\n",
    "    \n",
    "    # Bronze - early epoch with lower performance\n",
    "    bronze_epoch = min(5, len(hr10_values)-1)  # take epoch 5 or earlier\n",
    "    bronze_hr10 = hr10_values[bronze_epoch]\n",
    "    \n",
    "    print(\"\\nCheckpoint Analysis:\")\n",
    "    print(f\"Gold   - Epoch {gold_epoch}, HR@10: {gold_hr10:.4f}\")\n",
    "    print(f\"Silver - Epoch {silver_epoch}, HR@10: {silver_hr10:.4f}\")\n",
    "    print(f\"Bronze - Epoch {bronze_epoch}, HR@10: {bronze_hr10:.4f}\")\n",
    "    \n",
    "    return gold_epoch, silver_epoch, bronze_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "071785f9-d354-41c5-85ac-257bb8ac020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_progress(evaluation_metrics):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    if 'HR@10' in evaluation_metrics:\n",
    "        for trial_num, hr_values in evaluation_metrics['HR@10'].items():\n",
    "            if hr_values:  # Проверяем, что есть значения\n",
    "                plt.plot(range(len(hr_values)), hr_values, \n",
    "                        label=f'Trial {trial_num}')\n",
    "                print(f\"Plotting trial {trial_num} with {len(hr_values)} values. \"\n",
    "                      f\"Max HR@10: {max(hr_values):.4f}\")\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('HR@10')\n",
    "    plt.title('HR@10 over epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'VAE_metrics_{data_name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64c882c4-2876-4875-87d4-fd0dc44ec319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_convergence(evaluation_metrics):\n",
    "    best_epochs = []\n",
    "    best_values = []\n",
    "    \n",
    "    for trial_values in evaluation_metrics['HR@10'].values():\n",
    "        best_value = max(trial_values)\n",
    "        best_epoch = trial_values.index(best_value)\n",
    "        best_epochs.append(best_epoch)\n",
    "        best_values.append(best_value)\n",
    "    \n",
    "    print(f\"Statistics of best results achievement:\")\n",
    "    print(f\"Mean epoch to best result: {np.mean(best_epochs):.1f}\")\n",
    "    print(f\"Median epoch to best result: {np.median(best_epochs):.1f}\")\n",
    "    print(f\"Mean best HR@10: {np.mean(best_values):.4f}\")\n",
    "    print(f\"Best HR@10: {max(best_values):.4f}\")\n",
    "    print(f\"Worst HR@10: {min(best_values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95ad406-f1c9-441c-bdca-f1d6a40f2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(evaluation_metrics):\n",
    "    if not evaluation_metrics or not any(evaluation_metrics.values()):\n",
    "        print(\"No data to analyze\")\n",
    "        return {}\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # График для каждой метрики\n",
    "    for i, (metric_name, trials_data) in enumerate(evaluation_metrics.items(), 1):\n",
    "        if not trials_data:  # Если нет данных для этой метрики\n",
    "            continue\n",
    "            \n",
    "        plt.subplot(2, 3, i)\n",
    "        for trial_num, values in trials_data.items():\n",
    "            if values:  # Проверяем, что есть значения\n",
    "                plt.plot(values, label=f'Trial {trial_num}')\n",
    "        plt.title(f'{metric_name} over epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric_name)\n",
    "        plt.grid(True)\n",
    "        if i == 1:\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'VAE_metrics_{data_name}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Сохраняем сводную статистику только для метрик с данными\n",
    "    summary_stats = {}\n",
    "    for metric, trials_data in evaluation_metrics.items():\n",
    "        if trials_data and any(trials_data.values()):\n",
    "            summary_stats[metric] = {\n",
    "                'best_value': max(max(values) if values else float('-inf') \n",
    "                                for values in trials_data.values()),\n",
    "                'best_trial': max(trials_data.keys(),\n",
    "                                key=lambda x: max(trials_data[x]) if trials_data[x] else float('-inf')),\n",
    "                'mean_best': np.mean([max(values) if values else float('-inf') \n",
    "                                    for values in trials_data.values()]),\n",
    "                'std_best': np.std([max(values) if values else float('-inf') \n",
    "                                  for values in trials_data.values()])\n",
    "            }\n",
    "    \n",
    "    if summary_stats:  # Сохраняем только если есть данные\n",
    "        with open(f'VAE_summary_stats_{data_name}.json', 'w') as f:\n",
    "            json.dump(summary_stats, f, indent=4)\n",
    "    \n",
    "    return summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434d2013-2356-441a-93a8-efe3bd230143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_convergence(evaluation_metrics):\n",
    "    best_epochs = []\n",
    "    best_values = []\n",
    "    \n",
    "    for trial_values in evaluation_metrics['HR@10'].values():\n",
    "        best_value = max(trial_values)\n",
    "        best_epoch = trial_values.index(best_value)\n",
    "        best_epochs.append(best_epoch)\n",
    "        best_values.append(best_value)\n",
    "    \n",
    "    print(f\"Statistics of best results achievement:\")\n",
    "    print(f\"Mean epoch to best result: {np.mean(best_epochs):.1f}\")\n",
    "    print(f\"Median epoch to best result: {np.median(best_epochs):.1f}\")\n",
    "    print(f\"Mean best HR@10: {np.mean(best_values):.4f}\")\n",
    "    print(f\"Best HR@10: {max(best_values):.4f}\")\n",
    "    print(f\"Worst HR@10: {min(best_values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0dea078-9ef1-4517-8d9b-67cf6b03b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_progress(evaluation_metrics):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # График для HR@10\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for trial_num, hr_values in evaluation_metrics['HR@10'].items():\n",
    "        if hr_values:  # Проверяем, что есть значения\n",
    "            plt.plot(range(len(hr_values)), hr_values, \n",
    "                    label=f'Trial {trial_num}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('HR@10')\n",
    "    plt.title('HR@10 over epochs')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Добавляем среднее значение по всем trials\n",
    "    epochs_max = max(len(v) for v in evaluation_metrics['HR@10'].values())\n",
    "    mean_hr = np.zeros(epochs_max)\n",
    "    std_hr = np.zeros(epochs_max)\n",
    "    for epoch in range(epochs_max):\n",
    "        values = [v[epoch] for v in evaluation_metrics['HR@10'].values() \n",
    "                 if epoch < len(v)]\n",
    "        mean_hr[epoch] = np.mean(values)\n",
    "        std_hr[epoch] = np.std(values)\n",
    "    \n",
    "    plt.plot(range(epochs_max), mean_hr, 'k--', \n",
    "             linewidth=2, label='Mean HR@10')\n",
    "    plt.fill_between(range(epochs_max), \n",
    "                     mean_hr - std_hr, \n",
    "                     mean_hr + std_hr, \n",
    "                     color='gray', alpha=0.2)\n",
    "    \n",
    "    # Отмечаем лучшую эпоху\n",
    "    best_epoch = np.argmax(mean_hr)\n",
    "    plt.plot(best_epoch, mean_hr[best_epoch], 'r*', markersize=15,\n",
    "            label=f'Best: {mean_hr[best_epoch]:.4f} at epoch {best_epoch}')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Добавляем статистику\n",
    "    stats_text = (f\"Final mean HR@10: {mean_hr[-1]:.4f}\\n\"\n",
    "                 f\"Best mean HR@10: {np.max(mean_hr):.4f}\\n\"\n",
    "                 f\"Best epoch: {best_epoch}\")\n",
    "    plt.text(1.1, 0.5, stats_text, transform=plt.gca().transAxes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'VAE_metrics_{data_name}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Выводим статистику в консоль\n",
    "    print(\"\\nTraining progress statistics:\")\n",
    "    print(f\"Number of trials: {len(evaluation_metrics['HR@10'])}\")\n",
    "    print(f\"Average number of epochs per trial: {np.mean([len(v) for v in evaluation_metrics['HR@10'].values()]):.1f}\")\n",
    "    print(f\"Best mean HR@10: {np.max(mean_hr):.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d568bc",
   "metadata": {},
   "source": [
    "## NCF training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b14a838f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_losses_dict = {}\n",
    "test_losses_dict = {}\n",
    "HR10_dict = {}\n",
    "\n",
    "## PAY ATTENTION to define manualy the MLP_model and GMF_model checkpoints which will be used inside the NCF\n",
    "\n",
    "def NCF_objective(trial):\n",
    "    lr = trial.suggest_float('learning_rate', 0.0005, 0.005)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32,64,128])\n",
    "    beta = trial.suggest_float('beta',0, 4)\n",
    "    epochs = 20\n",
    "    MLP = MLP_model(hidden_size=8, num_layers=3, **kw_dict)\n",
    "    # EDIT HERE\n",
    "    MLP_checkpoint = torch.load(Path(checkpoints_path, 'MLP_model_ML1M_0.0001_64_27.pt'))\n",
    "    MLP.load_state_dict(MLP_checkpoint)\n",
    "    MLP.train()\n",
    "    GMF = GMF_model(hidden_size=8, **kw_dict)\n",
    "    # & EDIT HERE\n",
    "    GMF_checkpoint = torch.load(Path(checkpoints_path, 'GMF_best_ML1M_0.0001_32_17.pt'))\n",
    "    GMF.load_state_dict(GMF_checkpoint)\n",
    "    GMF.train()\n",
    "    model = NCF(factor_num=8, num_layers=3, dropout=0.5, model= 'NeuMF-pre', GMF_model= GMF, MLP_model=MLP, **kw_dict)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    hr10 = []\n",
    "    print(f'======================== new run - {recommender_name} ========================')\n",
    "    logger.info(f'======================== new run - {recommender_name} ========================')\n",
    "    \n",
    "    num_training = train_data.shape[0]\n",
    "    num_batches = int(np.ceil(num_training / batch_size))\n",
    "\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_matrix = sample_indices(train_data.copy(), **kw_dict)\n",
    "        perm = np.random.permutation(num_training)\n",
    "        loss = []\n",
    "        train_pos_loss=[]\n",
    "        train_neg_loss=[]\n",
    "        if epoch!=0 and epoch%10 == 0:\n",
    "            lr = 0.1*lr\n",
    "            optimizer.lr = lr\n",
    "        \n",
    "        for b in range(num_batches):\n",
    "            optimizer.zero_grad()\n",
    "            if (b + 1) * batch_size >= num_training:\n",
    "                batch_idx = perm[b * batch_size:]\n",
    "            else:\n",
    "                batch_idx = perm[b * batch_size: (b + 1) * batch_size]    \n",
    "            batch_matrix = torch.FloatTensor(train_matrix[batch_idx,:-2]).to(device)\n",
    "\n",
    "            batch_pos_idx = train_matrix[batch_idx,-2]\n",
    "            batch_neg_idx = train_matrix[batch_idx,-1]\n",
    "            \n",
    "            batch_pos_items = torch.Tensor(items_array[batch_pos_idx]).to(device)\n",
    "            batch_neg_items = torch.Tensor(items_array[batch_neg_idx]).to(device)\n",
    "            \n",
    "            pos_output = model(batch_matrix, batch_pos_items)\n",
    "            neg_output = model(batch_matrix, batch_neg_items)\n",
    "\n",
    "            pos_loss = -torch.log(pos_output).mean()\n",
    "            neg_loss = -torch.log(torch.ones_like(neg_output)-neg_output).mean()\n",
    "\n",
    "            batch_loss = pos_loss + beta*neg_loss\n",
    "            if batch_loss<torch.inf:\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            loss.append(batch_loss.item())\n",
    "            train_pos_loss.append(pos_loss.item())\n",
    "            train_neg_loss.append(neg_loss.item())\n",
    "            \n",
    "        print(f'train pos_loss = {np.mean(train_pos_loss)}, neg_loss = {np.mean(train_neg_loss)}')    \n",
    "        train_losses.append(np.mean(loss))\n",
    "        torch.save(model.state_dict(), Path(checkpoints_path, f'{recommender_name}2_{data_name}_{round(lr,5)}_{batch_size}_{trial.number}_{epoch}.pt'))\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        test_matrix = np.array(static_test_data)\n",
    "        test_tensor = torch.Tensor(test_matrix[:,:-2]).to(device)\n",
    "        \n",
    "        test_pos = test_matrix[:,-2]\n",
    "        test_neg = test_matrix[:,-1]\n",
    "        \n",
    "        row_indices = np.arange(test_matrix.shape[0])\n",
    "        test_tensor[row_indices,test_pos] = 0\n",
    "        \n",
    "        pos_items = torch.Tensor(items_array[test_pos]).to(device)\n",
    "        neg_items = torch.Tensor(items_array[test_neg]).to(device)\n",
    "        \n",
    "        pos_output = model(test_tensor, pos_items).to(device)\n",
    "        neg_output = model(test_tensor, neg_items).to(device)\n",
    "        \n",
    "        pos_loss = -torch.log(pos_output).mean()\n",
    "        neg_loss = -torch.log(torch.ones_like(neg_output)-neg_output).mean()\n",
    "        print(f'test pos_loss = {pos_loss}, neg_loss = {neg_loss}')\n",
    "        \n",
    "        hit_rate_at_10, hit_rate_at_50, hit_rate_at_100, MRR, MPR = recommender_evaluations(model, **kw_dict)\n",
    "        hr10.append(hit_rate_at_10)\n",
    "        print(hit_rate_at_10, hit_rate_at_50, hit_rate_at_100, MRR, MPR)\n",
    "                   \n",
    "        \n",
    "        test_losses.append(-hit_rate_at_10)\n",
    "        if epoch>5:\n",
    "            if test_losses[-2]<=test_losses[-1] and test_losses[-3]<=test_losses[-2] and test_losses[-4]<=test_losses[-3]:\n",
    "                logger.info(f'Early stop at trial with batch size = {batch_size} and lr = {lr}. Best results at epoch {np.argmin(test_losses)} with value {np.min(test_losses)}')\n",
    "                train_losses_dict[trial.number] = train_losses\n",
    "                test_losses_dict[trial.number] = test_losses\n",
    "                HR10_dict[trial.number] = hr10\n",
    "                return max(hr10)\n",
    "            \n",
    "    logger.info(f'Stop at trial with batch size = {batch_size} and lr = {lr}. Best results at epoch {np.argmin(test_losses)} with value {np.min(test_losses)}')\n",
    "    train_losses_dict[trial.number] = train_losses\n",
    "    test_losses_dict[trial.number] = test_losses\n",
    "    HR10_dict[trial.number] = hr10\n",
    "    return max(hr10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d135397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.395270636677742, neg_loss = 0.16510765701532365\n",
      "test pos_loss = 0.5951240062713623, neg_loss = 0.08138133585453033\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.005794701986754967 0.054635761589403975 0.09271523178807947 0.0008278145695364238 49.7377975088682\n",
      "train pos_loss = 0.6210036873817444, neg_loss = 0.07202535718679429\n",
      "test pos_loss = 0.5802581906318665, neg_loss = 0.0893411636352539\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0380794701986755 0.07119205298013245 0.09602649006622517 0.0008278145695364238 43.60665659871781\n",
      "train pos_loss = 0.5720695495605469, neg_loss = 0.09119329750537872\n",
      "test pos_loss = 0.5581821799278259, neg_loss = 0.09324529021978378\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.016556291390728478 0.07119205298013245 0.11009933774834436 0.0008278145695364238 39.59382486078218\n",
      "train pos_loss = 0.5666432499885559, neg_loss = 0.08644124865531921\n",
      "test pos_loss = 0.540945291519165, neg_loss = 0.0900702252984047\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.009933774834437087 0.052152317880794705 0.10016556291390728 0.0 37.037932074643855\n",
      "train pos_loss = 0.4777815222740173, neg_loss = 0.1090984359383583\n",
      "test pos_loss = 0.4804437458515167, neg_loss = 0.10470179468393326\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.012417218543046357 0.054635761589403975 0.09933774834437085 0.0008278145695364238 35.944462726063676\n",
      "train pos_loss = 0.5140062689781189, neg_loss = 0.08883558511734009\n",
      "test pos_loss = 0.5014573931694031, neg_loss = 0.09544198215007782\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.006622516556291391 0.052152317880794705 0.10099337748344371 0.0016556291390728477 35.70745459139603\n",
      "train pos_loss = 0.5165564894676209, neg_loss = 0.08645666539669036\n",
      "test pos_loss = 0.5144087076187134, neg_loss = 0.0839913859963417\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.023178807947019868 0.07367549668874172 0.11589403973509933 0.0041390728476821195 34.061717114141935\n",
      "train pos_loss = 0.4681764721870422, neg_loss = 0.09514587670564652\n",
      "test pos_loss = 0.4745218753814697, neg_loss = 0.09294669330120087\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0380794701986755 0.10264900662251655 0.1763245033112583 0.008278145695364239 32.456721531111725\n",
      "train pos_loss = 0.4519516885280609, neg_loss = 0.09453547149896621\n",
      "test pos_loss = 0.4591391980648041, neg_loss = 0.0953715369105339\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.041390728476821195 0.125 0.1978476821192053 0.0173841059602649 31.105456867457576\n",
      "train pos_loss = 0.45247253179550173, neg_loss = 0.0878957211971283\n",
      "test pos_loss = 0.47310304641723633, neg_loss = 0.08382314443588257\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.048841059602649006 0.1357615894039735 0.21605960264900662 0.015728476821192054 28.63861352199964\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.6215911865234375, neg_loss = 0.08778053522109985\n",
      "test pos_loss = 0.7092134952545166, neg_loss = 0.06627277284860611\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.01076158940397351 0.06456953642384106 0.11754966887417219 0.0 42.74757556348192\n",
      "train pos_loss = 0.8250955939292908, neg_loss = 0.03189196903258562\n",
      "test pos_loss = 0.9077582955360413, neg_loss = 0.009143504314124584\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.014072847682119206 0.048013245033112585 0.09437086092715231 0.0008278145695364238 40.45319970775525\n",
      "train pos_loss = 0.9153387427330018, neg_loss = 0.009703500755131244\n",
      "test pos_loss = 0.8829016089439392, neg_loss = 0.018005087971687317\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.014072847682119206 0.08774834437086093 0.13410596026490065 0.0 40.072811445338274\n",
      "train pos_loss = 0.8916063904762268, neg_loss = 0.018506783060729504\n",
      "test pos_loss = 0.9041649103164673, neg_loss = 0.01194324716925621\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.009105960264900662 0.06291390728476821 0.14486754966887416 0.0024834437086092716 39.86153632198633\n",
      "train pos_loss = 0.9110293745994568, neg_loss = 0.014652646332979202\n",
      "test pos_loss = 0.9231153130531311, neg_loss = 0.008897006511688232\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0041390728476821195 0.06456953642384106 0.12665562913907286 0.0008278145695364238 39.20041094468307\n",
      "train pos_loss = 0.9298563003540039, neg_loss = 0.007785348128527403\n",
      "test pos_loss = 0.9177194833755493, neg_loss = 0.011821124702692032\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.006622516556291391 0.058774834437086095 0.12665562913907286 0.0 38.73018974361985\n",
      "train pos_loss = 0.9157218933105469, neg_loss = 0.011785869859158993\n",
      "test pos_loss = 0.9065375924110413, neg_loss = 0.015668895095586777\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.008278145695364239 0.06539735099337748 0.13990066225165562 0.0016556291390728477 38.55889750083732\n",
      "train pos_loss = 0.8938414812088012, neg_loss = 0.014968937449157237\n",
      "test pos_loss = 0.8775059580802917, neg_loss = 0.02008955366909504\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.009105960264900662 0.0935430463576159 0.1564569536423841 0.0016556291390728477 38.161321251794725\n",
      "train pos_loss = 0.8839908957481384, neg_loss = 0.014228039421141148\n",
      "test pos_loss = 0.8677760362625122, neg_loss = 0.021302351728081703\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.014900662251655629 0.08195364238410596 0.15397350993377484 0.0024834437086092716 37.48114708019688\n",
      "train pos_loss = 0.8713267803192138, neg_loss = 0.018948239088058472\n",
      "test pos_loss = 0.8660130500793457, neg_loss = 0.02057112753391266\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0173841059602649 0.08112582781456953 0.1490066225165563 0.0041390728476821195 36.49665740180322\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.3051010549068451, neg_loss = 0.20610716938972473\n",
      "test pos_loss = 0.34609362483024597, neg_loss = 0.17565613985061646\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.02566225165562914 0.08940397350993377 0.1357615894039735 0.0033112582781456954 41.14642401734666\n",
      "train pos_loss = 0.31082910001277925, neg_loss = 0.1863398775458336\n",
      "test pos_loss = 0.3142695724964142, neg_loss = 0.181319460272789\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.14321192052980133 0.21274834437086093 0.009933774834437087 32.07351757287997\n",
      "train pos_loss = 0.2945501834154129, neg_loss = 0.179606893658638\n",
      "test pos_loss = 0.28826549649238586, neg_loss = 0.17604832351207733\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.060430463576158944 0.173841059602649 0.26572847682119205 0.015728476821192054 27.423212302485037\n",
      "train pos_loss = 0.28023722767829895, neg_loss = 0.17262351363897324\n",
      "test pos_loss = 0.3074832260608673, neg_loss = 0.15758082270622253\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.060430463576158944 0.19039735099337748 0.27483443708609273 0.014072847682119206 25.68103112249795\n",
      "train pos_loss = 0.2777767539024353, neg_loss = 0.1665148675441742\n",
      "test pos_loss = 0.2749122083187103, neg_loss = 0.18183347582817078\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07036423841059603 0.1912251655629139 0.2640728476821192 0.014072847682119206 24.694239918829613\n",
      "train pos_loss = 0.2697427958250046, neg_loss = 0.1660266637802124\n",
      "test pos_loss = 0.3044161796569824, neg_loss = 0.14934252202510834\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.057947019867549666 0.19536423841059603 0.2764900662251656 0.015728476821192054 23.54962284366671\n",
      "train pos_loss = 0.2611402630805969, neg_loss = 0.1617184966802597\n",
      "test pos_loss = 0.2855166494846344, neg_loss = 0.16127681732177734\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.062086092715231786 0.18294701986754966 0.2731788079470199 0.014072847682119206 24.286869945213923\n",
      "train pos_loss = 0.26033023446798326, neg_loss = 0.159433713555336\n",
      "test pos_loss = 0.2875475287437439, neg_loss = 0.15159432590007782\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06870860927152318 0.20943708609271522 0.2996688741721854 0.014072847682119206 22.60264313038776\n",
      "train pos_loss = 0.24797821044921875, neg_loss = 0.15865397453308105\n",
      "test pos_loss = 0.27697890996932983, neg_loss = 0.1626337617635727\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08195364238410596 0.20612582781456953 0.3129139072847682 0.013245033112582781 21.156281401129412\n",
      "train pos_loss = 0.2639936327934265, neg_loss = 0.1445856474339962\n",
      "test pos_loss = 0.2785317003726959, neg_loss = 0.16160210967063904\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06374172185430464 0.20033112582781457 0.29635761589403975 0.013245033112582781 21.63747157371442\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.4437727749347687, neg_loss = 0.14563921242952346\n",
      "test pos_loss = 0.4730861186981201, neg_loss = 0.11419110745191574\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.016556291390728478 0.07450331125827815 0.10678807947019868 0.0 40.09159091220707\n",
      "train pos_loss = 0.4248102277517319, neg_loss = 0.1398099184036255\n",
      "test pos_loss = 0.37640103697776794, neg_loss = 0.16114938259124756\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.03228476821192053 0.10182119205298014 0.1490066225165563 0.0074503311258278145 36.108679002842145\n",
      "train pos_loss = 0.34768070578575133, neg_loss = 0.16150551438331603\n",
      "test pos_loss = 0.4078550636768341, neg_loss = 0.12334401905536652\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06374172185430464 0.1423841059602649 0.2052980132450331 0.012417218543046357 31.832028809220258\n",
      "train pos_loss = 0.37917875647544863, neg_loss = 0.12570958733558654\n",
      "test pos_loss = 0.3362409174442291, neg_loss = 0.1494331657886505\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06788079470198675 0.17880794701986755 0.2582781456953642 0.024006622516556293 27.222465433049177\n",
      "train pos_loss = 0.3384040266275406, neg_loss = 0.13314920514822007\n",
      "test pos_loss = 0.3564263582229614, neg_loss = 0.13658232986927032\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.058774834437086095 0.15894039735099338 0.25662251655629137 0.01903973509933775 26.60646464171611\n",
      "train pos_loss = 0.3473666936159134, neg_loss = 0.12453461959958076\n",
      "test pos_loss = 0.358402818441391, neg_loss = 0.12986038625240326\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06788079470198675 0.17135761589403972 0.2541390728476821 0.012417218543046357 25.261663836280274\n",
      "train pos_loss = 0.3397760599851608, neg_loss = 0.12313506677746773\n",
      "test pos_loss = 0.3087671995162964, neg_loss = 0.1437757909297943\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06870860927152318 0.19039735099337748 0.27566225165562913 0.012417218543046357 23.65661928462717\n",
      "train pos_loss = 0.32420512437820437, neg_loss = 0.12177731841802597\n",
      "test pos_loss = 0.31065627932548523, neg_loss = 0.13733503222465515\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07533112582781457 0.18956953642384106 0.2897350993377483 0.012417218543046357 21.892818457645106\n",
      "train pos_loss = 0.31632028967142106, neg_loss = 0.11995265409350395\n",
      "test pos_loss = 0.3267003297805786, neg_loss = 0.12813487648963928\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.061258278145695365 0.19205298013245034 0.29387417218543044 0.008278145695364239 22.48017260460189\n",
      "train pos_loss = 0.31111736297607423, neg_loss = 0.11452078521251678\n",
      "test pos_loss = 0.323508620262146, neg_loss = 0.13336022198200226\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06291390728476821 0.1804635761589404 0.28725165562913907 0.009105960264900662 22.28975811459048\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.4814035751317677, neg_loss = 0.12246539208449815\n",
      "test pos_loss = 0.5399375557899475, neg_loss = 0.09420344233512878\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.016556291390728478 0.06291390728476821 0.1183774834437086 0.0008278145695364238 43.10078624020877\n",
      "train pos_loss = 0.48973541040169566, neg_loss = 0.10282258571762788\n",
      "test pos_loss = 0.5172087550163269, neg_loss = 0.08884231001138687\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.03642384105960265 0.10099337748344371 0.14735099337748345 0.006622516556291391 37.927251234499\n",
      "train pos_loss = 0.45363740230861466, neg_loss = 0.10243463045672367\n",
      "test pos_loss = 0.4915332794189453, neg_loss = 0.08446399867534637\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.050496688741721855 0.1490066225165563 0.20695364238410596 0.008278145695364239 32.64605871142007\n",
      "train pos_loss = 0.4426058436694898, neg_loss = 0.09269338885420247\n",
      "test pos_loss = 0.45601943135261536, neg_loss = 0.09183868765830994\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.061258278145695365 0.1564569536423841 0.2293046357615894 0.011589403973509934 29.408449242063675\n",
      "train pos_loss = 0.4187558528624083, neg_loss = 0.0943789160565326\n",
      "test pos_loss = 0.4096065163612366, neg_loss = 0.1039852648973465\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06539735099337748 0.173841059602649 0.24751655629139072 0.011589403973509934 26.85549457329719\n",
      "train pos_loss = 0.40649741888046265, neg_loss = 0.09051162239752318\n",
      "test pos_loss = 0.4230342209339142, neg_loss = 0.09341659396886826\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08278145695364239 0.19619205298013245 0.28228476821192056 0.015728476821192054 24.01783633119245\n",
      "train pos_loss = 0.3966234671442132, neg_loss = 0.09183310403635628\n",
      "test pos_loss = 0.40587377548217773, neg_loss = 0.09424908459186554\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07201986754966887 0.19536423841059603 0.2889072847682119 0.009933774834437087 22.945080710084223\n",
      "train pos_loss = 0.3786564328168568, neg_loss = 0.08727944054101643\n",
      "test pos_loss = 0.3962278962135315, neg_loss = 0.09025263041257858\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06539735099337748 0.1945364238410596 0.28725165562913907 0.011589403973509934 22.065506306179266\n",
      "train pos_loss = 0.37149060713617427, neg_loss = 0.0877214474113364\n",
      "test pos_loss = 0.40586987137794495, neg_loss = 0.08092445880174637\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07119205298013245 0.201158940397351 0.29635761589403975 0.01076158940397351 20.293674625047252\n",
      "train pos_loss = 0.36613159273800094, neg_loss = 0.08650794821350198\n",
      "test pos_loss = 0.4009142220020294, neg_loss = 0.08248315006494522\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0728476821192053 0.21357615894039736 0.3220198675496689 0.015728476821192054 19.256813004499236\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.29616211825295496, neg_loss = 0.21638230822588267\n",
      "test pos_loss = 0.3176824748516083, neg_loss = 0.18642446398735046\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.043874172185430466 0.14735099337748345 0.20943708609271522 0.009105960264900662 33.65892570676412\n",
      "train pos_loss = 0.2923895936263235, neg_loss = 0.1968073829224235\n",
      "test pos_loss = 0.27295663952827454, neg_loss = 0.21627724170684814\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.059602649006622516 0.1763245033112583 0.2508278145695364 0.009105960264900662 27.843828288585765\n",
      "train pos_loss = 0.28377326460261093, neg_loss = 0.18493936563792981\n",
      "test pos_loss = 0.2876551151275635, neg_loss = 0.19817012548446655\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07201986754966887 0.1945364238410596 0.26572847682119205 0.014900662251655629 25.85188264767466\n",
      "train pos_loss = 0.28133502132014226, neg_loss = 0.18585268368846491\n",
      "test pos_loss = 0.29199719429016113, neg_loss = 0.188668355345726\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07201986754966887 0.20364238410596028 0.3038079470198676 0.011589403973509934 23.53380597848124\n",
      "train pos_loss = 0.277462888705103, neg_loss = 0.1807952833018805\n",
      "test pos_loss = 0.3202655613422394, neg_loss = 0.179042786359787\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.057119205298013245 0.1870860927152318 0.277317880794702 0.0033112582781456954 24.196277992913235\n",
      "train pos_loss = 0.2792171216324756, neg_loss = 0.17189600906874003\n",
      "test pos_loss = 0.3177945911884308, neg_loss = 0.1858845353126526\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052980132450331126 0.173841059602649 0.277317880794702 0.009933774834437087 23.90469432806234\n",
      "train pos_loss = 0.2619725301077491, neg_loss = 0.18435377196261757\n",
      "test pos_loss = 0.36027368903160095, neg_loss = 0.15736228227615356\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06788079470198675 0.18625827814569537 0.2781456953642384 0.009933774834437087 23.386385939345537\n",
      "train pos_loss = 0.26400620607953323, neg_loss = 0.1731323082196085\n",
      "test pos_loss = 0.34825441241264343, neg_loss = 0.1660534143447876\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06622516556291391 0.1879139072847682 0.2806291390728477 0.01076158940397351 22.39949679843146\n",
      "train pos_loss = 0.2876509616249486, neg_loss = 0.1635125079437306\n",
      "test pos_loss = 0.34160804748535156, neg_loss = 0.16424724459648132\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.048841059602649006 0.173841059602649 0.26655629139072845 0.005794701986754967 22.418251780988847\n",
      "train pos_loss = 0.28040957529293864, neg_loss = 0.1598613191592066\n",
      "test pos_loss = 0.3630204200744629, neg_loss = 0.15190865099430084\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04552980132450331 0.17798013245033112 0.26490066225165565 0.0041390728476821195 22.733095541700646\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.6540471762418747, neg_loss = 0.07577756755053996\n",
      "test pos_loss = 0.8012570142745972, neg_loss = 0.03731609880924225\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.018211920529801324 0.07201986754966887 0.1183774834437086 0.0008278145695364238 42.96014835533983\n",
      "train pos_loss = 0.8794926881790162, neg_loss = 0.01708317482843995\n",
      "test pos_loss = 0.8963465690612793, neg_loss = 0.012842266820371151\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.014072847682119206 0.06291390728476821 0.10678807947019868 0.0016556291390728477 42.554884032507296\n",
      "train pos_loss = 0.8747325897216797, neg_loss = 0.018252496793866157\n",
      "test pos_loss = 0.8475784659385681, neg_loss = 0.022799501195549965\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0173841059602649 0.06291390728476821 0.12417218543046357 0.0033112582781456954 40.347207123563535\n",
      "train pos_loss = 0.8021345138549805, neg_loss = 0.031187020242214203\n",
      "test pos_loss = 0.7667118310928345, neg_loss = 0.03947136551141739\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.014072847682119206 0.07781456953642384 0.13245033112582782 0.0 36.10253344067253\n",
      "train pos_loss = 0.7440545201301575, neg_loss = 0.03734305389225483\n",
      "test pos_loss = 0.7019835710525513, neg_loss = 0.04350205138325691\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.023178807947019868 0.09685430463576158 0.14403973509933773 0.0024834437086092716 34.069674515357555\n",
      "train pos_loss = 0.6966925501823426, neg_loss = 0.03992904331535101\n",
      "test pos_loss = 0.6562063097953796, neg_loss = 0.04684435576200485\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04304635761589404 0.12665562913907286 0.1912251655629139 0.006622516556291391 30.736380356922545\n",
      "train pos_loss = 0.5958568513393402, neg_loss = 0.0554781511425972\n",
      "test pos_loss = 0.6932878494262695, neg_loss = 0.03104143589735031\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.14735099337748345 0.21937086092715233 0.009933774834437087 28.66855783488172\n",
      "train pos_loss = 0.6052149832248688, neg_loss = 0.04512854143977165\n",
      "test pos_loss = 0.6154272556304932, neg_loss = 0.04435202479362488\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052980132450331126 0.1597682119205298 0.25 0.009933774834437087 26.046386017695276\n",
      "train pos_loss = 0.5580774664878845, neg_loss = 0.05075603872537613\n",
      "test pos_loss = 0.5954672694206238, neg_loss = 0.04756516218185425\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.054635761589403975 0.16142384105960264 0.2433774834437086 0.009105960264900662 25.32520062444786\n",
      "train pos_loss = 0.5703622043132782, neg_loss = 0.04767133109271526\n",
      "test pos_loss = 0.6187127828598022, neg_loss = 0.04429551959037781\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.1597682119205298 0.24254966887417218 0.006622516556291391 24.210919611150004\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.7983969807624817, neg_loss = 0.055375892197480424\n",
      "test pos_loss = 0.9632235169410706, neg_loss = 0.013734334148466587\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.012417218543046357 0.07698675496688742 0.12582781456953643 0.0 47.522089745774494\n",
      "train pos_loss = 0.9582716703414917, neg_loss = 0.020233972696587443\n",
      "test pos_loss = 0.9776362776756287, neg_loss = 0.009916773997247219\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.014072847682119206 0.06374172185430464 0.10927152317880795 0.0008278145695364238 46.78048443679233\n",
      "train pos_loss = 0.9840071260929107, neg_loss = 0.007123893732205034\n",
      "test pos_loss = 0.9892985224723816, neg_loss = 0.005020162556320429\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0074503311258278145 0.054635761589403975 0.09850993377483444 0.0 46.12584740201866\n",
      "train pos_loss = 0.9868578553199768, neg_loss = 0.010488290386274458\n",
      "test pos_loss = 0.9827472567558289, neg_loss = 0.013276736252009869\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.004966887417218543 0.04552980132450331 0.09105960264900662 0.0016556291390728477 46.13632668731184\n",
      "train pos_loss = 0.9833283603191376, neg_loss = 0.01298322221264243\n",
      "test pos_loss = 0.9739795923233032, neg_loss = 0.01733691804111004\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.011589403973509934 0.04304635761589404 0.0902317880794702 0.0016556291390728477 46.17545261698107\n",
      "train pos_loss = 0.9754023373126983, neg_loss = 0.014063811069354415\n",
      "test pos_loss = 0.9785853624343872, neg_loss = 0.02227938175201416\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.01076158940397351 0.042218543046357616 0.08857615894039735 0.0024834437086092716 46.17667683255286\n",
      "train pos_loss = 0.976581460237503, neg_loss = 0.01973746921867132\n",
      "test pos_loss = 0.9772286415100098, neg_loss = 0.02214689366519451\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.011589403973509934 0.04056291390728477 0.09271523178807947 0.0016556291390728477 45.872263388511186\n",
      "train pos_loss = 0.9758908212184906, neg_loss = 0.01991691756993532\n",
      "test pos_loss = 0.976863443851471, neg_loss = 0.022291136905550957\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.01076158940397351 0.037251655629139076 0.08857615894039735 0.0008278145695364238 45.748593131465064\n",
      "train pos_loss = 0.9777523636817932, neg_loss = 0.02071001073345542\n",
      "test pos_loss = 0.9742773175239563, neg_loss = 0.021723758429288864\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.01076158940397351 0.03559602649006623 0.08609271523178808 0.0008278145695364238 45.97757041198275\n",
      "train pos_loss = 0.9740383803844452, neg_loss = 0.018311533331871032\n",
      "test pos_loss = 0.9721611738204956, neg_loss = 0.02288837544620037\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.012417218543046357 0.03394039735099338 0.08278145695364239 0.0 45.991893734170894\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.5914448782017356, neg_loss = 0.08678465630663068\n",
      "test pos_loss = 0.6169774532318115, neg_loss = 0.08186221867799759\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04552980132450331 0.09933774834437085 0.14321192052980133 0.009105960264900662 42.55028098195801\n",
      "train pos_loss = 0.6040494096906561, neg_loss = 0.07146318158821056\n",
      "test pos_loss = 0.6035218834877014, neg_loss = 0.06383198499679565\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.02152317880794702 0.06705298013245033 0.11009933774834436 0.0033112582781456954 37.90137131731472\n",
      "train pos_loss = 0.568545517168547, neg_loss = 0.0703444478935317\n",
      "test pos_loss = 0.5785689949989319, neg_loss = 0.06512469053268433\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.03228476821192053 0.09933774834437085 0.15397350993377484 0.006622516556291391 34.187590959217005\n",
      "train pos_loss = 0.5350661873817444, neg_loss = 0.0697840397295199\n",
      "test pos_loss = 0.5472848415374756, neg_loss = 0.0642901286482811\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04552980132450331 0.1183774834437086 0.1837748344370861 0.009105960264900662 28.738631934201866\n",
      "train pos_loss = 0.49903697559708043, neg_loss = 0.07131083740999825\n",
      "test pos_loss = 0.5037988424301147, neg_loss = 0.07175672799348831\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.046357615894039736 0.14321192052980133 0.2251655629139073 0.006622516556291391 26.999633714700984\n",
      "train pos_loss = 0.4821619611037405, neg_loss = 0.0724319474477517\n",
      "test pos_loss = 0.5407097935676575, neg_loss = 0.060295622795820236\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.046357615894039736 0.14072847682119205 0.23096026490066227 0.006622516556291391 25.84267654657603\n",
      "train pos_loss = 0.48776199472577947, neg_loss = 0.06544233172347672\n",
      "test pos_loss = 0.43468713760375977, neg_loss = 0.0929819718003273\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.048841059602649006 0.1456953642384106 0.2359271523178808 0.009105960264900662 24.314194436772677\n",
      "train pos_loss = 0.4665248017562063, neg_loss = 0.07053879864121738\n",
      "test pos_loss = 0.496670663356781, neg_loss = 0.0654478520154953\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.050496688741721855 0.1564569536423841 0.24006622516556292 0.0074503311258278145 23.415669175818934\n",
      "train pos_loss = 0.44265444027750117, neg_loss = 0.0710930143924136\n",
      "test pos_loss = 0.5123412013053894, neg_loss = 0.05812004581093788\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04718543046357616 0.1490066225165563 0.24254966887417218 0.004966887417218543 23.111157794531593\n",
      "train pos_loss = 0.44923122619327743, neg_loss = 0.06634346787866793\n",
      "test pos_loss = 0.4757511019706726, neg_loss = 0.0699593722820282\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.055463576158940396 0.16473509933774835 0.25248344370860926 0.004966887417218543 22.295830223825813\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.573915421962738, neg_loss = 0.10098872147500515\n",
      "test pos_loss = 0.7433829307556152, neg_loss = 0.044853705912828445\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0074503311258278145 0.043874172185430466 0.0935430463576159 0.0024834437086092716 42.43246247534432\n",
      "train pos_loss = 0.6311172604560852, neg_loss = 0.07037394046783448\n",
      "test pos_loss = 0.5197357535362244, neg_loss = 0.09737436473369598\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.02152317880794702 0.06870860927152318 0.10264900662251655 0.0041390728476821195 37.92695742276177\n",
      "train pos_loss = 0.5883406221866607, neg_loss = 0.0719682164490223\n",
      "test pos_loss = 0.579186737537384, neg_loss = 0.07140404731035233\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.039735099337748346 0.11920529801324503 0.17052980132450332 0.005794701986754967 33.82764709684626\n",
      "train pos_loss = 0.5073481529951096, neg_loss = 0.08952836580574512\n",
      "test pos_loss = 0.5037767291069031, neg_loss = 0.08284018188714981\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04552980132450331 0.1382450331125828 0.2119205298013245 0.0074503311258278145 30.8251115015543\n",
      "train pos_loss = 0.4737515777349472, neg_loss = 0.084688950330019\n",
      "test pos_loss = 0.5217937231063843, neg_loss = 0.07924588024616241\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.048013245033112585 0.14403973509933773 0.21688741721854304 0.012417218543046357 28.36769461599786\n",
      "train pos_loss = 0.4738769710063934, neg_loss = 0.08268163949251175\n",
      "test pos_loss = 0.5065110325813293, neg_loss = 0.07961258292198181\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04718543046357616 0.1498344370860927 0.23178807947019867 0.008278145695364239 26.932203921015557\n",
      "train pos_loss = 0.4765802353620529, neg_loss = 0.07848940454423428\n",
      "test pos_loss = 0.48923832178115845, neg_loss = 0.07942693680524826\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.054635761589403975 0.16225165562913907 0.24089403973509935 0.01076158940397351 25.111844334624177\n",
      "train pos_loss = 0.437175926566124, neg_loss = 0.07923761159181594\n",
      "test pos_loss = 0.4938350319862366, neg_loss = 0.07481679320335388\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.05132450331125828 0.1630794701986755 0.2392384105960265 0.011589403973509934 24.35807032285994\n",
      "train pos_loss = 0.42972066104412077, neg_loss = 0.08294048123061656\n",
      "test pos_loss = 0.49124473333358765, neg_loss = 0.07209409028291702\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052980132450331126 0.16556291390728478 0.2533112582781457 0.015728476821192054 22.62276923438542\n",
      "train pos_loss = 0.4233592629432678, neg_loss = 0.07916827164590359\n",
      "test pos_loss = 0.4922935962677002, neg_loss = 0.06743864715099335\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.05380794701986755 0.17052980132450332 0.25496688741721857 0.011589403973509934 22.55421316237408\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.14092947425026642, neg_loss = 0.4295516970910524\n",
      "test pos_loss = 0.14055190980434418, neg_loss = 0.41468101739883423\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0347682119205298 0.11423841059602649 0.18211920529801323 0.008278145695364239 39.88580027461604\n",
      "train pos_loss = 0.1284850439742992, neg_loss = 0.4296756371071464\n",
      "test pos_loss = 0.13055868446826935, neg_loss = 0.4091196358203888\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04966887417218543 0.14817880794701987 0.20447019867549668 0.011589403973509934 34.33280741032373\n",
      "train pos_loss = 0.11034873402432392, neg_loss = 0.4450645791856866\n",
      "test pos_loss = 0.10994242876768112, neg_loss = 0.4404280185699463\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07450331125827815 0.1945364238410596 0.24834437086092714 0.013245033112582781 30.843988905668777\n",
      "train pos_loss = 0.10957164003660805, neg_loss = 0.4258959889411926\n",
      "test pos_loss = 0.11100991070270538, neg_loss = 0.4162275493144989\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08609271523178808 0.21357615894039736 0.2889072847682119 0.014900662251655629 27.001249679255533\n",
      "train pos_loss = 0.10421441691486459, neg_loss = 0.4211710895362653\n",
      "test pos_loss = 0.10759010165929794, neg_loss = 0.4034513831138611\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10596026490066225 0.24006622516556292 0.3162251655629139 0.024006622516556293 24.454685415773017\n",
      "train pos_loss = 0.0990552137556829, neg_loss = 0.4044115370825717\n",
      "test pos_loss = 0.11669988930225372, neg_loss = 0.37123557925224304\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10596026490066225 0.2541390728476821 0.33195364238410596 0.023178807947019868 23.011996333229508\n",
      "train pos_loss = 0.09583328781943572, neg_loss = 0.3945149355813077\n",
      "test pos_loss = 0.09834293276071548, neg_loss = 0.4038149118423462\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10678807947019868 0.26158940397350994 0.347682119205298 0.024834437086092714 21.880674239174496\n",
      "train pos_loss = 0.09318992652391132, neg_loss = 0.38879960618521037\n",
      "test pos_loss = 0.10020792484283447, neg_loss = 0.3895297050476074\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10347682119205298 0.2599337748344371 0.36920529801324503 0.022350993377483443 21.18299378490238\n",
      "train pos_loss = 0.0917803735325211, neg_loss = 0.37773616533530385\n",
      "test pos_loss = 0.10508130490779877, neg_loss = 0.36832669377326965\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.11754966887417219 0.27566225165562913 0.3849337748344371 0.024006622516556293 19.914730937004794\n",
      "train pos_loss = 0.09140727669000626, neg_loss = 0.3624534669675325\n",
      "test pos_loss = 0.10454536229372025, neg_loss = 0.36163726449012756\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.12086092715231789 0.27483443708609273 0.3783112582781457 0.027317880794701987 19.225522054488376\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.09633030830637405, neg_loss = 0.5794003801910501\n",
      "test pos_loss = 0.02095108851790428, neg_loss = 0.8267251253128052\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06539735099337748 0.19950331125827814 0.28394039735099336 0.01076158940397351 23.015815885813016\n",
      "train pos_loss = 0.00892564248734791, neg_loss = 0.8990952654888755\n",
      "test pos_loss = 0.005322561599314213, neg_loss = 0.9267780184745789\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.062086092715231786 0.1837748344370861 0.2723509933774834 0.0074503311258278145 23.025683063320358\n",
      "train pos_loss = 0.003077925605650403, neg_loss = 0.9467884427622745\n",
      "test pos_loss = 0.003194814082235098, neg_loss = 0.9467720985412598\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052980132450331126 0.17466887417218543 0.2541390728476821 0.006622516556291391 23.321747357163463\n",
      "train pos_loss = 0.0019320399120548054, neg_loss = 0.9590593450947812\n",
      "test pos_loss = 0.0025076575111597776, neg_loss = 0.9544281363487244\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.17466887417218543 0.24503311258278146 0.004966887417218543 23.355168442268916\n",
      "train pos_loss = 0.0015006218669249823, neg_loss = 0.9642823997296786\n",
      "test pos_loss = 0.002176006557419896, neg_loss = 0.9582772254943848\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.057119205298013245 0.17301324503311258 0.2433774834437086 0.006622516556291391 23.789446674149055\n",
      "train pos_loss = 0.0013620051138691213, neg_loss = 0.9668510054287157\n",
      "test pos_loss = 0.0019802539609372616, neg_loss = 0.9603782892227173\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.16804635761589404 0.24172185430463577 0.009105960264900662 23.878765442255233\n",
      "train pos_loss = 0.0013006991020550853, neg_loss = 0.9695332238548681\n",
      "test pos_loss = 0.0015873841475695372, neg_loss = 0.9644936919212341\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.16142384105960264 0.21937086092715233 0.009105960264900662 24.127697436590488\n",
      "train pos_loss = 0.0008693322995800133, neg_loss = 0.972552848489661\n",
      "test pos_loss = 0.0015191257698461413, neg_loss = 0.966618001461029\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.055463576158940396 0.1564569536423841 0.2052980132450331 0.004966887417218543 24.366541894615608\n",
      "train pos_loss = 0.0012177468758493074, neg_loss = 0.9734971742880972\n",
      "test pos_loss = 0.0014380647335201502, neg_loss = 0.9686957597732544\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.054635761589403975 0.1390728476821192 0.20033112582781457 0.0024834437086092716 24.56523208189123\n",
      "train pos_loss = 0.0010902161899905064, neg_loss = 0.9758449071332028\n",
      "test pos_loss = 0.0012127944501116872, neg_loss = 0.9707663655281067\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.055463576158940396 0.13327814569536423 0.201158940397351 0.0024834437086092716 24.8249371732569\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.09518037775629445, neg_loss = 0.5806601753360346\n",
      "test pos_loss = 0.022543679922819138, neg_loss = 0.8212770223617554\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06539735099337748 0.19370860927152317 0.26986754966887416 0.009933774834437087 28.397345117142688\n",
      "train pos_loss = 0.010629165697058565, neg_loss = 0.8838025864801908\n",
      "test pos_loss = 0.008109886199235916, neg_loss = 0.9052546620368958\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06374172185430464 0.17466887417218543 0.25 0.009933774834437087 27.641367517349586\n",
      "train pos_loss = 0.005299626592252599, neg_loss = 0.9205230756809837\n",
      "test pos_loss = 0.007125042844563723, neg_loss = 0.9118415117263794\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.059602649006622516 0.16473509933774835 0.24006622516556292 0.009933774834437087 28.127674911024048\n",
      "train pos_loss = 0.0054721546261326266, neg_loss = 0.9176331131081832\n",
      "test pos_loss = 0.007301547098904848, neg_loss = 0.907046914100647\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.057947019867549666 0.16887417218543047 0.23096026490066227 0.009933774834437087 28.37161210582708\n",
      "train pos_loss = 0.005627695654862021, neg_loss = 0.9164882553251166\n",
      "test pos_loss = 0.007247541099786758, neg_loss = 0.9039852023124695\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.15811258278145696 0.22019867549668873 0.009105960264900662 28.62480437035163\n",
      "train pos_loss = 0.005995628705836441, neg_loss = 0.9111627465800235\n",
      "test pos_loss = 0.008998489007353783, neg_loss = 0.8948022723197937\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.057947019867549666 0.1490066225165563 0.20860927152317882 0.0074503311258278145 29.159370341859745\n",
      "train pos_loss = 0.007997195309910336, neg_loss = 0.9030519284700093\n",
      "test pos_loss = 0.010317712090909481, neg_loss = 0.8889526724815369\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.054635761589403975 0.14321192052980133 0.21026490066225165 0.009105960264900662 29.35475514709192\n",
      "train pos_loss = 0.0076682866845083865, neg_loss = 0.9061281241868672\n",
      "test pos_loss = 0.008473622612655163, neg_loss = 0.8945896625518799\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.14321192052980133 0.21026490066225165 0.008278145695364239 30.02070393374742\n",
      "train pos_loss = 0.006025347711616441, neg_loss = 0.9085073533811068\n",
      "test pos_loss = 0.007594624999910593, neg_loss = 0.8971107006072998\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04304635761589404 0.12748344370860928 0.20447019867549668 0.009105960264900662 30.326072265934894\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.20865951870617114, neg_loss = 0.29683090040558263\n",
      "test pos_loss = 0.187165766954422, neg_loss = 0.3184308707714081\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.042218543046357616 0.12996688741721854 0.18625827814569537 0.009933774834437087 36.13428959260064\n",
      "train pos_loss = 0.18864784821083672, neg_loss = 0.30598066668761403\n",
      "test pos_loss = 0.18156760931015015, neg_loss = 0.30325454473495483\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07119205298013245 0.18874172185430463 0.25579470198675497 0.009105960264900662 29.765234628259616\n",
      "train pos_loss = 0.1753317792164652, neg_loss = 0.2912343787519555\n",
      "test pos_loss = 0.18248040974140167, neg_loss = 0.2772928476333618\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0902317880794702 0.2185430463576159 0.2947019867549669 0.02152317880794702 25.697484579780653\n",
      "train pos_loss = 0.1698330029060966, neg_loss = 0.2818963668848339\n",
      "test pos_loss = 0.1727445125579834, neg_loss = 0.2745828628540039\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0902317880794702 0.222682119205298 0.30960264900662254 0.01903973509933775 22.96819390007664\n",
      "train pos_loss = 0.16043591656182943, neg_loss = 0.27106884278749166\n",
      "test pos_loss = 0.16933469474315643, neg_loss = 0.2666436731815338\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10016556291390728 0.23013245033112584 0.30711920529801323 0.018211920529801324 22.151666598110577\n",
      "train pos_loss = 0.1535429609449286, neg_loss = 0.2640427280413477\n",
      "test pos_loss = 0.17218559980392456, neg_loss = 0.2550097405910492\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09602649006622517 0.23841059602649006 0.31788079470198677 0.02566225165562914 21.613232105396133\n",
      "train pos_loss = 0.1493794604351646, neg_loss = 0.2549879872485211\n",
      "test pos_loss = 0.17616787552833557, neg_loss = 0.24887488782405853\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10927152317880795 0.24834437086092714 0.33112582781456956 0.020695364238410598 20.903480885587747\n",
      "train pos_loss = 0.14830004815992556, neg_loss = 0.2502964946784471\n",
      "test pos_loss = 0.1649976521730423, neg_loss = 0.25534215569496155\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.1076158940397351 0.26572847682119205 0.32864238410596025 0.023178807947019868 20.157150104498992\n",
      "train pos_loss = 0.14013266524201945, neg_loss = 0.25473415224175705\n",
      "test pos_loss = 0.1919739842414856, neg_loss = 0.22345347702503204\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08940397350993377 0.24834437086092714 0.3228476821192053 0.015728476821192054 20.458772337037328\n",
      "train pos_loss = 0.14338308768837074, neg_loss = 0.24380461557915337\n",
      "test pos_loss = 0.17047424614429474, neg_loss = 0.24106895923614502\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10016556291390728 0.24172185430463577 0.33278145695364236 0.015728476821192054 19.28940162301604\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.2014992660597751, neg_loss = 0.30442074254939433\n",
      "test pos_loss = 0.18078874051570892, neg_loss = 0.3296672999858856\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.057119205298013245 0.14321192052980133 0.18294701986754966 0.01076158940397351 35.354978444012204\n",
      "train pos_loss = 0.18207261672145442, neg_loss = 0.3119627111836484\n",
      "test pos_loss = 0.19274672865867615, neg_loss = 0.28866949677467346\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07201986754966887 0.18874172185430463 0.2706953642384106 0.011589403973509934 27.801078680824414\n",
      "train pos_loss = 0.17520903521462491, neg_loss = 0.29476413601323176\n",
      "test pos_loss = 0.16677196323871613, neg_loss = 0.3000648021697998\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07698675496688742 0.20364238410596028 0.29718543046357615 0.01903973509933775 24.890383737716256\n",
      "train pos_loss = 0.16056061810568759, neg_loss = 0.2822150054730867\n",
      "test pos_loss = 0.171970397233963, neg_loss = 0.28204286098480225\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0802980132450331 0.20033112582781457 0.2897350993377483 0.0173841059602649 24.88881674178451\n",
      "train pos_loss = 0.1523119070028004, neg_loss = 0.2719931461309132\n",
      "test pos_loss = 0.17878857254981995, neg_loss = 0.26305320858955383\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08774834437086093 0.22185430463576158 0.31788079470198677 0.018211920529801324 23.035941989810606\n",
      "train pos_loss = 0.15226249004665174, neg_loss = 0.2637229499063994\n",
      "test pos_loss = 0.1729818880558014, neg_loss = 0.259098619222641\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09188741721854304 0.23178807947019867 0.3211920529801324 0.020695364238410598 22.01722324403414\n",
      "train pos_loss = 0.14576559317739388, neg_loss = 0.26234303806957443\n",
      "test pos_loss = 0.1649215966463089, neg_loss = 0.25554797053337097\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10016556291390728 0.23178807947019867 0.326158940397351 0.018211920529801324 20.790094039343344\n",
      "train pos_loss = 0.14636259094664925, neg_loss = 0.25719548761844635\n",
      "test pos_loss = 0.1690988689661026, neg_loss = 0.2482730746269226\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.1076158940397351 0.23758278145695363 0.32367549668874174 0.022350993377483443 20.73473501119419\n",
      "train pos_loss = 0.14289807959606773, neg_loss = 0.24539987507619357\n",
      "test pos_loss = 0.15431450307369232, neg_loss = 0.2537707984447479\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09602649006622517 0.24172185430463577 0.3253311258278146 0.02152317880794702 20.282509779034\n",
      "train pos_loss = 0.1348840241369448, neg_loss = 0.2542792213590522\n",
      "test pos_loss = 0.17002615332603455, neg_loss = 0.23929312825202942\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10347682119205298 0.26490066225165565 0.3518211920529801 0.026490066225165563 18.746535469932297\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.19922587275505066, neg_loss = 0.34438478397695643\n",
      "test pos_loss = 0.16272924840450287, neg_loss = 0.3844674825668335\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.030629139072847682 0.1076158940397351 0.16390728476821192 0.0033112582781456954 37.991400130452384\n",
      "train pos_loss = 0.17020988778064125, neg_loss = 0.348253552850924\n",
      "test pos_loss = 0.18450503051280975, neg_loss = 0.3346180021762848\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.05380794701986755 0.152317880794702 0.21688741721854304 0.009933774834437087 30.593857180073318\n",
      "train pos_loss = 0.1628994628002769, neg_loss = 0.345938326496827\n",
      "test pos_loss = 0.19196729362010956, neg_loss = 0.32854562997817993\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.16556291390728478 0.24834437086092714 0.0074503311258278145 27.12869052026225\n",
      "train pos_loss = 0.1653990961219135, neg_loss = 0.33123476254312617\n",
      "test pos_loss = 0.19603775441646576, neg_loss = 0.3409023880958557\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052980132450331126 0.13990066225165562 0.2119205298013245 0.0074503311258278145 25.875510008207158\n",
      "train pos_loss = 0.15200196284996836, neg_loss = 0.34049571501581294\n",
      "test pos_loss = 0.20896697044372559, neg_loss = 0.332865834236145\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.048841059602649006 0.15562913907284767 0.22350993377483444 0.005794701986754967 26.385714089839805\n",
      "train pos_loss = 0.182523701536028, neg_loss = 0.3186182567947789\n",
      "test pos_loss = 0.2088235467672348, neg_loss = 0.32130464911460876\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.048013245033112585 0.152317880794702 0.2326158940397351 0.0074503311258278145 24.63907676517199\n",
      "train pos_loss = 0.15940275004035548, neg_loss = 0.34330570854638753\n",
      "test pos_loss = 0.21066239476203918, neg_loss = 0.32095879316329956\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04966887417218543 0.15314569536423842 0.222682119205298 0.005794701986754967 24.757287020768604\n",
      "train pos_loss = 0.15414330010351382, neg_loss = 0.3431531018332431\n",
      "test pos_loss = 0.19925081729888916, neg_loss = 0.3478809595108032\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.041390728476821195 0.15894039735099338 0.2293046357615894 0.005794701986754967 24.494154125802332\n",
      "train pos_loss = 0.14725459719959058, neg_loss = 0.35205901923932525\n",
      "test pos_loss = 0.2458031326532364, neg_loss = 0.3019634485244751\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.05132450331125828 0.152317880794702 0.23509933774834438 0.005794701986754967 25.097765855550403\n",
      "train pos_loss = 0.16714556123081006, neg_loss = 0.31840207231672185\n",
      "test pos_loss = 0.28081274032592773, neg_loss = 0.2855217158794403\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.042218543046357616 0.14072847682119205 0.22433774834437087 0.006622516556291391 26.26657343040874\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.18765101385743996, neg_loss = 0.32727198067464325\n",
      "test pos_loss = 0.18123473227024078, neg_loss = 0.3299742341041565\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06374172185430464 0.12665562913907286 0.1672185430463576 0.012417218543046357 38.4450699369872\n",
      "train pos_loss = 0.16628076371393705, neg_loss = 0.34005365089366313\n",
      "test pos_loss = 0.18519677221775055, neg_loss = 0.3081328570842743\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08195364238410596 0.1771523178807947 0.24089403973509935 0.011589403973509934 31.6570394354114\n",
      "train pos_loss = 0.1588720812609321, neg_loss = 0.32796736296854523\n",
      "test pos_loss = 0.15949122607707977, neg_loss = 0.32156530022621155\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08857615894039735 0.19950331125827814 0.2731788079470199 0.014900662251655629 27.36665354307577\n",
      "train pos_loss = 0.15215112347351878, neg_loss = 0.3053127025303088\n",
      "test pos_loss = 0.15246663987636566, neg_loss = 0.3140503466129303\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10016556291390728 0.22019867549668873 0.30049668874172186 0.0173841059602649 24.41695509185538\n",
      "train pos_loss = 0.144730922422911, neg_loss = 0.3051573257697256\n",
      "test pos_loss = 0.1432475745677948, neg_loss = 0.310259073972702\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08940397350993377 0.2326158940397351 0.3170529801324503 0.019867549668874173 23.366284319659332\n",
      "train pos_loss = 0.13770820788646998, neg_loss = 0.29713285126184164\n",
      "test pos_loss = 0.1471685767173767, neg_loss = 0.2875882387161255\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10927152317880795 0.24420529801324503 0.33774834437086093 0.022350993377483443 21.50760678587586\n",
      "train pos_loss = 0.1372977601070153, neg_loss = 0.2781798337635241\n",
      "test pos_loss = 0.1515100747346878, neg_loss = 0.2744017243385315\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10182119205298014 0.2458609271523179 0.35016556291390727 0.024834437086092714 20.518048855015664\n",
      "train pos_loss = 0.13266437226220182, neg_loss = 0.2808880037383029\n",
      "test pos_loss = 0.15403123199939728, neg_loss = 0.26134949922561646\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09933774834437085 0.25165562913907286 0.34602649006622516 0.022350993377483443 20.3707267531257\n",
      "train pos_loss = 0.12677595058554098, neg_loss = 0.2714077281324487\n",
      "test pos_loss = 0.16436314582824707, neg_loss = 0.24568487703800201\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09850993377483444 0.2541390728476821 0.3617549668874172 0.024834437086092714 19.643224407528667\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.2637959212064743, neg_loss = 0.23676277697086334\n",
      "test pos_loss = 0.2627439796924591, neg_loss = 0.23697350919246674\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.016556291390728478 0.06374172185430464 0.09685430463576158 0.0033112582781456954 40.75048821716998\n",
      "train pos_loss = 0.26213974356651304, neg_loss = 0.23712458312511445\n",
      "test pos_loss = 0.26667800545692444, neg_loss = 0.23169471323490143\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.046357615894039736 0.11092715231788079 0.16639072847682118 0.01076158940397351 36.82660798266911\n",
      "train pos_loss = 0.26852325201034544, neg_loss = 0.22944912314414978\n",
      "test pos_loss = 0.2658998668193817, neg_loss = 0.23022258281707764\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06870860927152318 0.14321192052980133 0.1945364238410596 0.018211920529801324 34.481378212096836\n",
      "train pos_loss = 0.2638245403766632, neg_loss = 0.23182318210601807\n",
      "test pos_loss = 0.26681065559387207, neg_loss = 0.22683864831924438\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07698675496688742 0.16804635761589404 0.23509933774834438 0.02152317880794702 32.2441732235653\n",
      "train pos_loss = 0.2656728208065033, neg_loss = 0.22579321563243865\n",
      "test pos_loss = 0.26559820771217346, neg_loss = 0.22443465888500214\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09105960264900662 0.19205298013245034 0.24503311258278146 0.022350993377483443 29.891279863514676\n",
      "train pos_loss = 0.2607226550579071, neg_loss = 0.22524994909763335\n",
      "test pos_loss = 0.2618074417114258, neg_loss = 0.2230721265077591\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09850993377483444 0.20943708609271522 0.2682119205298013 0.023178807947019868 27.323340796151424\n",
      "train pos_loss = 0.25704280138015745, neg_loss = 0.22310779690742494\n",
      "test pos_loss = 0.25920015573501587, neg_loss = 0.2196965515613556\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10264900662251655 0.22764900662251655 0.29635761589403975 0.024006622516556293 25.000832466588708\n",
      "train pos_loss = 0.2504988074302673, neg_loss = 0.22067214846611022\n",
      "test pos_loss = 0.2559109926223755, neg_loss = 0.21585729718208313\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.11258278145695365 0.23841059602649006 0.3220198675496689 0.023178807947019868 23.421325051759855\n",
      "train pos_loss = 0.2482321858406067, neg_loss = 0.21421035528182983\n",
      "test pos_loss = 0.25050026178359985, neg_loss = 0.21385258436203003\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.12086092715231789 0.25662251655629137 0.3485099337748344 0.024834437086092714 22.27915640774017\n",
      "train pos_loss = 0.23896387219429016, neg_loss = 0.21556670367717742\n",
      "test pos_loss = 0.2431221306324005, neg_loss = 0.21257872879505157\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.11754966887417219 0.26986754966887416 0.34933774834437087 0.028973509933774833 21.30641919883417\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.34475486278533934, neg_loss = 0.21038919389247895\n",
      "test pos_loss = 0.3878600001335144, neg_loss = 0.15626811981201172\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.016556291390728478 0.054635761589403975 0.10016556291390728 0.0016556291390728477 39.523922151642104\n",
      "train pos_loss = 0.31657716631889343, neg_loss = 0.21934673190116882\n",
      "test pos_loss = 0.35944366455078125, neg_loss = 0.17545907199382782\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.030629139072847682 0.11672185430463576 0.1763245033112583 0.0041390728476821195 34.1250825121295\n",
      "train pos_loss = 0.311325341463089, neg_loss = 0.20111187398433686\n",
      "test pos_loss = 0.2905407249927521, neg_loss = 0.22685474157333374\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04304635761589404 0.13327814569536423 0.1879139072847682 0.004966887417218543 34.25560837637678\n",
      "train pos_loss = 0.29917954206466674, neg_loss = 0.1906771779060364\n",
      "test pos_loss = 0.28841572999954224, neg_loss = 0.19066424667835236\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.04304635761589404 0.1423841059602649 0.22185430463576158 0.006622516556291391 27.180548291876505\n",
      "train pos_loss = 0.28737713098526, neg_loss = 0.18289330899715422\n",
      "test pos_loss = 0.32540231943130493, neg_loss = 0.18595166504383087\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.03890728476821192 0.12582781456953643 0.1879139072847682 0.004966887417218543 30.75765722355749\n",
      "train pos_loss = 0.2593255937099457, neg_loss = 0.1996709555387497\n",
      "test pos_loss = 0.3103528916835785, neg_loss = 0.1654817909002304\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06456953642384106 0.18625827814569537 0.26076158940397354 0.008278145695364239 23.093112857005774\n",
      "train pos_loss = 0.277809864282608, neg_loss = 0.17096928358078003\n",
      "test pos_loss = 0.25747761130332947, neg_loss = 0.19620509445667267\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06870860927152318 0.18543046357615894 0.27980132450331124 0.011589403973509934 22.225241953965533\n",
      "train pos_loss = 0.25032021999359133, neg_loss = 0.17951868176460267\n",
      "test pos_loss = 0.31138643622398376, neg_loss = 0.15230931341648102\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06788079470198675 0.19039735099337748 0.27566225165562913 0.013245033112582781 22.17179270210822\n",
      "train pos_loss = 0.2564390629529953, neg_loss = 0.17010606527328492\n",
      "test pos_loss = 0.2994796931743622, neg_loss = 0.15885068476200104\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.0728476821192053 0.20695364238410596 0.3038079470198676 0.012417218543046357 21.15784839706109\n",
      "train pos_loss = 0.2588818997144699, neg_loss = 0.15852778851985933\n",
      "test pos_loss = 0.2654705345630646, neg_loss = 0.1768820732831955\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.07864238410596026 0.2077814569536424 0.30132450331125826 0.014900662251655629 20.95849713337683\n",
      "======================== new run - MLP ========================\n",
      "train pos_loss = 0.3367608547210693, neg_loss = 0.18963636457920074\n",
      "test pos_loss = 0.3944772779941559, neg_loss = 0.15476542711257935\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.014072847682119206 0.061258278145695365 0.10596026490066225 0.0008278145695364238 44.91149900789574\n",
      "train pos_loss = 0.36141233444213866, neg_loss = 0.16971023380756378\n",
      "test pos_loss = 0.3268023729324341, neg_loss = 0.19182546436786652\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.041390728476821195 0.08278145695364239 0.12748344370860928 0.009105960264900662 40.39500049947996\n",
      "train pos_loss = 0.34094430804252623, neg_loss = 0.17837705016136168\n",
      "test pos_loss = 0.3648778200149536, neg_loss = 0.16504189372062683\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.052152317880794705 0.10264900662251655 0.1357615894039735 0.014900662251655629 39.24830225784526\n",
      "train pos_loss = 0.3637658774852753, neg_loss = 0.15946772694587708\n",
      "test pos_loss = 0.36095839738845825, neg_loss = 0.16042257845401764\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.059602649006622516 0.10182119205298014 0.1423841059602649 0.011589403973509934 37.226828537346385\n",
      "train pos_loss = 0.36371479034423826, neg_loss = 0.15481986999511718\n",
      "test pos_loss = 0.3873414099216461, neg_loss = 0.14126703143119812\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.06870860927152318 0.11754966887417219 0.16804635761589404 0.014072847682119206 34.58768909233722\n",
      "train pos_loss = 0.37503068447113036, neg_loss = 0.14356182217597963\n",
      "test pos_loss = 0.36735889315605164, neg_loss = 0.14650332927703857\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.076158940397351 0.15314569536423842 0.19701986754966888 0.019867549668874173 31.591445965083427\n",
      "train pos_loss = 0.35758031606674195, neg_loss = 0.14617775678634642\n",
      "test pos_loss = 0.35017290711402893, neg_loss = 0.15094305574893951\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.08774834437086093 0.18129139072847683 0.23344370860927152 0.0173841059602649 29.50589680156543\n",
      "train pos_loss = 0.3371530413627625, neg_loss = 0.15275697112083436\n",
      "test pos_loss = 0.3543238639831543, neg_loss = 0.14274805784225464\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.09105960264900662 0.19950331125827814 0.26572847682119205 0.01903973509933775 27.69653067100721\n",
      "train pos_loss = 0.3424905061721802, neg_loss = 0.14131850600242615\n",
      "test pos_loss = 0.33753496408462524, neg_loss = 0.1467527151107788\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.1076158940397351 0.21605960264900662 0.2913907284768212 0.020695364238410598 25.773483882467463\n",
      "train pos_loss = 0.3362680435180664, neg_loss = 0.13680142164230347\n",
      "test pos_loss = 0.35513386130332947, neg_loss = 0.13380075991153717\n",
      "Debug shapes in recommender_evaluations:\n",
      "static_test_data shape: (1208, 3383)\n",
      "items_array shape: (3381, 3381)\n",
      "num_items: 3381\n",
      "0.10182119205298014 0.2293046357615894 0.31043046357615894 0.020695364238410598 24.611850210858876\n",
      "Best hyperparameters: {'learning_rate': 0.00122095321344422, 'batch_size': 256, 'hidden_dim': 128, 'beta': 0.43458012541312785}\n",
      "Best metric value: 0.12086092715231789\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "\n",
    "logger.setLevel(logging.INFO)  # Setup the root logger.\n",
    "logger.addHandler(logging.FileHandler(f\"{recommender_name}_{data_name}_Optuna.log\", mode=\"w\"))\n",
    "\n",
    "optuna.logging.enable_propagation()  # Propagate logs to the root logger.\n",
    "optuna.logging.disable_default_handler()  # Stop showing logs in sys.stderr.\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "logger.info(\"Start optimization.\")\n",
    "study.optimize(MLP_objective, n_trials=20)\n",
    "\n",
    "with open(f\"{recommender_name}_{data_name}_Optuna.log\") as f:\n",
    "    assert f.readline().startswith(\"A new study created\")\n",
    "    assert f.readline() == \"Start optimization.\\n\"\n",
    "    \n",
    "    \n",
    "# Print best hyperparameters and corresponding metric value\n",
    "print(\"Best hyperparameters: {}\".format(study.best_params))\n",
    "print(\"Best metric value: {}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7cff4d-2692-46e4-98ec-071eb3b5ac38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82576ff3",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e5880",
   "metadata": {},
   "source": [
    "## Load the trained recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "933a25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP_ML1M_0.002_1024_19_8.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\")}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2b061a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = hidden_dim_dict[(data_name, recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name, recommender_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "652def72",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_recommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoints_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecommender_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/mikhail/PI4Rec/code/help_functions.ipynb:182\u001b[0m, in \u001b[0;36mload_recommender\u001b[0;34m(data_name, hidden_dim, checkpoints_path, recommender_path, **kw_dict)\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[1;32m      2\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      3\u001b[0m   {\n\u001b[1;32m      4\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3e035cd6\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m      7\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### This notebook includes the framework\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms functions that are being used in all notebooks.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Imports\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m    ]\n\u001b[1;32m     11\u001b[0m   },\n\u001b[1;32m     12\u001b[0m   {\n\u001b[1;32m     13\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     15\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maca5f6cb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m     18\u001b[0m    },\n\u001b[1;32m     19\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     20\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport os\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKMP_DUPLICATE_LIB_OK\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_dir = os.getcwd()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom pathlib import Path\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pickle\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom collections import defaultdict\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport time\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn as nn\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn.functional as F\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport copy\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn as nn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m    ]\n\u001b[1;32m     36\u001b[0m   },\n\u001b[1;32m     37\u001b[0m   {\n\u001b[1;32m     38\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf6255d17\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     41\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Help Functions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m    ]\n\u001b[1;32m     44\u001b[0m   },\n\u001b[1;32m     45\u001b[0m   {\n\u001b[1;32m     46\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     48\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m57327551\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     49\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     50\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     51\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# a function that samples different train data variation for a diverse training\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef sample_indices(data, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_items = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    pop_array = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_array\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    matrix = np.array(data)[:,:num_items] # keep only items columns, remove demographic features columns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    zero_indices = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    one_indices = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for row in matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        zero_idx = np.where(row == 0)[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        one_idx = np.where(row == 1)[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        probs = pop_array[zero_idx]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        probs = probs/ np.sum(probs)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sampled_zero = np.random.choice(zero_idx, p = probs) # sample negative interactions according to items popularity \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        zero_indices.append(sampled_zero)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sampled_one = np.random.choice(one_idx) # sample positive interactions from user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        data.iloc[row, sampled_one] = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        one_indices.append(sampled_one)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    data[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = one_indices\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    data[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = zero_indices\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return np.array(data)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m    ]\n\u001b[1;32m     78\u001b[0m   },\n\u001b[1;32m     79\u001b[0m   {\n\u001b[1;32m     80\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m     82\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma4dc1cca\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     83\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     84\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     85\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# a function that returns a specific item\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms rank in user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms recommendations list\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef get_index_in_the_list(user_tensor, original_user_tensor, item_id, recommender, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    top_k_list = list(get_top_k(user_tensor, original_user_tensor, recommender, **kw).keys())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return top_k_list.index(item_id)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m    ]\n\u001b[1;32m     91\u001b[0m   },\n\u001b[1;32m     92\u001b[0m   {\n\u001b[1;32m     93\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m     95\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m99fbbe32\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     97\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     98\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# returns a dictionary of items and recommendations scores for a specific user\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef get_top_k(user_tensor, original_user_tensor, model, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    all_items_tensor = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_items_tensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_items = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    item_prob_dict = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    output_model = [float(i) for i in recommender_run(user_tensor, model, all_items_tensor, None, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, **kw).cpu().detach().numpy()]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    original_user_vector = np.array(original_user_tensor.cpu())[:num_items]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    catalog = np.ones_like(original_user_vector)- original_user_vector\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    output = catalog*output_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for i in range(len(output)):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if catalog[i] > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            item_prob_dict[i]=output[i]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    sorted_items_by_prob  = sorted(item_prob_dict.items(), key=lambda item: item[1],reverse=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return dict(sorted_items_by_prob)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    114\u001b[0m    ]\n\u001b[1;32m    115\u001b[0m   },\n\u001b[1;32m    116\u001b[0m   {\n\u001b[1;32m    117\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    118\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    119\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m50da5217\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    120\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    121\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    122\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# a function that wraps the different recommenders types \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# returns user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms scores with respect to a certain item or for all items \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef recommender_run(user_tensor, recommender, item_tensor=None, item_id=None, wanted_output=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    output_type = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    user_tensor = user_tensor.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if item_tensor is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_tensor = item_tensor.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if output_type == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if wanted_output == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return recommender(user_tensor, item_tensor)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return recommender(user_tensor, item_tensor).squeeze()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if wanted_output == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return recommender(user_tensor).squeeze()[item_id]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return recommender(user_tensor).squeeze()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m    ]\n\u001b[1;32m    143\u001b[0m   },\n\u001b[1;32m    144\u001b[0m   {\n\u001b[1;32m    145\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    146\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    147\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mba9c0c58\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    148\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    149\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    150\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef recommender_evaluations(recommender, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    static_test_data = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatic_test_data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].copy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    items_array = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems_array\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_items = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDebug shapes in recommender_evaluations:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mstatic_test_data shape: \u001b[39m\u001b[38;5;132;01m{static_test_data.shape}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mitems_array shape: \u001b[39m\u001b[38;5;132;01m{items_array.shape}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mnum_items: \u001b[39m\u001b[38;5;132;01m{num_items}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    counter_10 = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    counter_50 = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    counter_100 = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    RR = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    PR = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    temp_test_array = np.array(static_test_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    n = temp_test_array.shape[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for i in range(n):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_id = temp_test_array[i][-2]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_tensor = torch.Tensor(temp_test_array[i][:-2]).to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if user_tensor.shape[0] != num_items:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mWarning: user_tensor shape \u001b[39m\u001b[38;5;132;01m{user_tensor.shape}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match num_items \u001b[39m\u001b[38;5;132;01m{num_items}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            continue\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_tensor[item_id] = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if isinstance(recommender, VAE):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            predictions = recommender(user_tensor)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            sorted_indices = torch.argsort(predictions, descending=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            index = (sorted_indices == item_id).nonzero().item() + 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            index = get_index_in_the_list(user_tensor, user_tensor, item_id, recommender, **kw) + 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if index <= 10:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            counter_10 += 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if index <= 50:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            counter_50 += 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if index <= 100:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            counter_100 += 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        RR += np.reciprocal(index)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        PR += index/num_items\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return counter_10/n, counter_50/n, counter_100/n, RR/n, PR*100/n\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m    ]\n\u001b[1;32m    199\u001b[0m   },\n\u001b[1;32m    200\u001b[0m   {\n\u001b[1;32m    201\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    202\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    203\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m163acc2a\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    204\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    205\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    206\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# get user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms top recommended item\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef get_user_recommended_item(user_tensor, recommender, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    all_items_tensor = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_items_tensor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_items = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    user_res = recommender_run(user_tensor, recommender, all_items_tensor, None, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, **kw)[:num_items]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    user_tensor = user_tensor[:num_items]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    user_catalog = torch.ones_like(user_tensor)-user_tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    user_recommenations = torch.mul(user_res, user_catalog)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return(torch.argmax(user_recommenations))\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m    ]\n\u001b[1;32m    217\u001b[0m   },\n\u001b[1;32m    218\u001b[0m   {\n\u001b[1;32m    219\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    221\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m48d782ce\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    223\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    224\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# calculate the ndcg score of the restored recommendations list after perturbating the user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef get_ndcg(ranked_list, target_item, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if target_item not in ranked_list:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return 0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    target_idx = torch.tensor(ranked_list.index(target_item), device=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dcg = torch.reciprocal(torch.log2(target_idx + 2))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return dcg.item()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m    ]\n\u001b[1;32m    236\u001b[0m   },\n\u001b[1;32m    237\u001b[0m   {\n\u001b[1;32m    238\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    240\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m158e03a8-7a5f-45e9-a55e-29039358f592\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    241\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    242\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    243\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef get_ndcg_negative(ranked_list, target_item, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if target_item not in ranked_list:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return 1.0  # Best case for negative item\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    target_idx = ranked_list.index(target_item)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dcg = 1 / torch.log2(torch.tensor(len(ranked_list) - target_idx + 1, dtype=torch.float, device=device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return dcg.item()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m    ]\n\u001b[1;32m    252\u001b[0m   },\n\u001b[1;32m    253\u001b[0m   {\n\u001b[1;32m    254\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    255\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    256\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m69c742a0-cc27-4b8e-8873-48664e2345f3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    257\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    258\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    259\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom ipynb.fs.defs.recommenders_architecture import *\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimportlib.reload(ipynb.fs.defs.recommenders_architecture)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom ipynb.fs.defs.recommenders_architecture import *\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m    ]\n\u001b[1;32m    264\u001b[0m   },\n\u001b[1;32m    265\u001b[0m   {\n\u001b[1;32m    266\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    267\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    268\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m245c6c80-f73e-47c2-a47e-6b867a61b500\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    269\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m    271\u001b[0m    },\n\u001b[1;32m    272\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    273\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef load_recommender(data_name, hidden_dim, checkpoints_path, recommender_path, **kw_dict):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    recommender_name = kw_dict[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecommender_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    device = kw_dict[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Создаем модель в зависимости от типа\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if recommender_name == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        recommender = MLP(hidden_dim, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    elif recommender_name == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVAE\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        VAE_config = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124menc_dims\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [512,128],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: 0.5,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124manneal_cap\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: 0.2,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mtotal_anneal_steps\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: 200000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Pinterest_VAE_config = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124menc_dims\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: [256,64],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: 0.5,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124manneal_cap\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: 0.2,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mtotal_anneal_steps\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m: 200000\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        }\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if data_name == \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPinterest\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            recommender = VAE(Pinterest_VAE_config, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            recommender = VAE(VAE_config, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    elif recommender_name == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNCF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                         model=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeuMF-pre\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, GMF_model=GMF_temp, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                         MLP_model=MLP_temp, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        raise ValueError(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mUnknown recommender type: \u001b[39m\u001b[38;5;132;01m{recommender_name}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Загружаем веса модели\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    recommender_checkpoint = torch.load(Path(checkpoints_path, recommender_path), \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                                      map_location=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    recommender.load_state_dict(recommender_checkpoint)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    recommender.to(device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    recommender.eval()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Отключаем градиенты\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for param in recommender.parameters():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        param.requires_grad = False\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return recommender\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m    ]\n\u001b[1;32m    321\u001b[0m   },\n\u001b[1;32m    322\u001b[0m   {\n\u001b[1;32m    323\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    324\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    325\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2fd001ce-bfeb-42db-a591-84dfb461d38c\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    326\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m    328\u001b[0m    },\n\u001b[1;32m    329\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    330\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# metrics calculations (will be used in all metrics notebooks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender_model, expl_dict, **kw_dict):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    device = kw_dict[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    POS_masked = user_tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    NEG_masked = user_tensor\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    POS_masked[item_id]=0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    NEG_masked[item_id]=0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    user_hist_size = np.sum(user_vector)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    bins=[0]+[len(x) for x in np.array_split(np.arange(user_hist_size), num_of_bins, axis=0)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    POS_at_5 = [0]*(len(bins))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    POS_at_10=[0]*(len(bins))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    POS_at_20=[0]*(len(bins))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    DEL = [0]*(len(bins))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    INS = [0]*(len(bins))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    NDCG = [0]*(len(bins))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    POS_sim_items = expl_dict\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    NEG_sim_items  = list(sorted(dict(POS_sim_items).items(), key=lambda item: item[1],reverse=False))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    total_items=0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for i in range(len(bins)):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        total_items += bins[i]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        POS_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for j in POS_sim_items[:total_items]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            POS_masked[j[0]] = 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        POS_masked = user_tensor - POS_masked # remove the masked items from the user history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        NEG_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for j in NEG_sim_items[:total_items]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            NEG_masked[j[0]] = 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        NEG_masked = user_tensor - NEG_masked # remove the masked items from the user history \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        POS_ranked_list = get_top_k(POS_masked, user_tensor, recommender_model, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if item_id in list(POS_ranked_list.keys()):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            POS_index = list(POS_ranked_list.keys()).index(item_id)+1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            POS_index = num_items\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        NEG_index = get_index_in_the_list(NEG_masked, user_tensor, item_id, recommender_model, **kw_dict)+1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # for pos:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        POS_at_5[i] = 1 if POS_index <=5 else 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        POS_at_10[i] = 1 if POS_index <=10 else 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        POS_at_20[i] = 1 if POS_index <=20 else 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # for del:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        DEL[i] = float(recommender_run(POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # for ins:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        INS[i] = float(recommender_run(user_tensor-POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        #for NDCG:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        NDCG[i]= get_ndcg(list(POS_ranked_list.keys()),item_id, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    res = [DEL, INS, NDCG, POS_at_5, POS_at_10, POS_at_20]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for i in range(len(res)):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        res[i] = np.array(res[i])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    return res\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m    ]\n\u001b[1;32m    399\u001b[0m   },\n\u001b[1;32m    400\u001b[0m   {\n\u001b[1;32m    401\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    402\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf5d8897d-aa7f-4cad-b2d3-8d45c4dcae8b\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    403\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    404\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## LXR Related\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    406\u001b[0m    ]\n\u001b[1;32m    407\u001b[0m   },\n\u001b[1;32m    408\u001b[0m   {\n\u001b[1;32m    409\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    410\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[1;32m    411\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8f87ef82-d16a-4c78-afc3-e9f864255844\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: []\n\u001b[1;32m    414\u001b[0m    },\n\u001b[1;32m    415\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    416\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass LXR_loss(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, lambda_pos, lambda_neg, alpha):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super(LXR_loss, self).__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.lambda_pos = lambda_pos\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.lambda_neg = lambda_neg\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.alpha = alpha\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, user_tensors, items_tensors, items_ids, pos_masks):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        neg_masks = torch.sub(torch.ones_like(pos_masks), pos_masks)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x_masked_pos = user_tensors * pos_masks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        x_masked_neg = user_tensors * neg_masks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if output_type==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x_masked_res_pos = recommender_run(x_masked_pos, recommender, items_tensors, item_id=items_ids, wanted_output = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x_masked_res_neg = recommender_run(x_masked_neg, recommender, items_tensors, item_id=items_ids, wanted_output = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x_masked_res_pos_before = recommender_run(x_masked_pos, recommender, items_tensors, item_id=items_ids, wanted_output = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x_masked_res_neg_before = recommender_run(x_masked_neg, recommender, items_tensors, item_id=items_ids, wanted_output = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, **kw_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            rows=torch.arange(len(items_ids))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x_masked_res_pos = x_masked_res_pos_before[rows, items_ids] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            x_masked_res_neg = x_masked_res_neg_before[rows, items_ids] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pos_loss = -torch.mean(torch.log(x_masked_res_pos))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        neg_loss = torch.mean(torch.log(x_masked_res_neg))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        l1 = x_masked_pos[x_masked_pos>0].mean()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        combined_loss = self.lambda_pos*pos_loss + self.lambda_neg*neg_loss + self.alpha*l1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return combined_loss, pos_loss, neg_loss, l1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m    ]\n\u001b[1;32m    447\u001b[0m   }\n\u001b[1;32m    448\u001b[0m  ],\n\u001b[1;32m    449\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    450\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    451\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython 3 (ipykernel)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    454\u001b[0m   },\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    456\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    459\u001b[0m    },\n\u001b[1;32m    460\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    461\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    462\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    463\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    464\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    465\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.12.4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m   }\n\u001b[1;32m    467\u001b[0m  },\n\u001b[1;32m    468\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    469\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    470\u001b[0m }\n",
      "File \u001b[0;32m/storage/mikhail/PI4Rec/code/recommenders_architecture.ipynb:31\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, hidden_size, **kw)\u001b[0m\n\u001b[1;32m      1\u001b[0m {\n\u001b[1;32m      2\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      3\u001b[0m   {\n\u001b[1;32m      4\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1a9956ce\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m      7\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### This notebook presents the architectures of the three recommendation systems tested within this framework\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# 1. Imports\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m    ]\n\u001b[1;32m     11\u001b[0m   },\n\u001b[1;32m     12\u001b[0m   {\n\u001b[1;32m     13\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     15\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6583e643\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     17\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     18\u001b[0m     {\n\u001b[1;32m     19\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     22\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  from .autonotebook import tqdm as notebook_tqdm\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m      ]\n\u001b[1;32m     25\u001b[0m     }\n\u001b[1;32m     26\u001b[0m    ],\n\u001b[1;32m     27\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport os\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKMP_DUPLICATE_LIB_OK\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport_dir = os.getcwd()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom pathlib import Path\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pickle\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom collections import defaultdict\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport time\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn as nn\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn.functional as F\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport copy\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport optuna\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport logging\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m    ]\n\u001b[1;32m     44\u001b[0m   },\n\u001b[1;32m     45\u001b[0m   {\n\u001b[1;32m     46\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m30bd66af\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     49\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# 2. MLP recommender Architecture\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m    ]\n\u001b[1;32m     52\u001b[0m   },\n\u001b[1;32m     53\u001b[0m   {\n\u001b[1;32m     54\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     56\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4cb9ccf2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     57\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     58\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     59\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MLP(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, hidden_size, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super(MLP, self).__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.users_fc = nn.Linear(user_size, hidden_size, bias = True).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.items_fc = nn.Linear(item_size, hidden_size, bias = True).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.sigmoid = nn.Sigmoid()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, user_tensor, item_tensor):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_vec = self.users_fc(user_tensor.to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_vec = self.items_fc(item_tensor.to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        output = torch.matmul(user_vec, item_vec.T).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.sigmoid(output).to(self.device)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m    ]\n\u001b[1;32m     76\u001b[0m   },\n\u001b[1;32m     77\u001b[0m   {\n\u001b[1;32m     78\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc09c694d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     81\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# 3. VAE recommender Architecture\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m    ]\n\u001b[1;32m     84\u001b[0m   },\n\u001b[1;32m     85\u001b[0m   {\n\u001b[1;32m     86\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     87\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     88\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf65bb266\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     90\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m     91\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass VAE(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, model_conf, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super().__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_features = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_items = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.demographic = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemographic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.demographic:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.num_items = num_features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.items_only = num_items\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.num_items = num_items\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.enc_dims = [self.num_items] + model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menc_dims\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dec_dims = self.enc_dims[::-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dims = self.enc_dims + self.dec_dims[1:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.softmax = nn.Softmax(dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.total_anneal_steps = model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_anneal_steps\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.anneal_cap = model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manneal_cap\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.eps = 1e-6\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.anneal = 0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.update_count = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.encoder = nn.ModuleList()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for i, (d_in, d_out) in enumerate(zip(self.enc_dims[:-1], self.enc_dims[1:])):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if i == len(self.enc_dims[:-1]) - 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                d_out *= 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.encoder.append(nn.Linear(d_in, d_out))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if i != len(self.enc_dims[:-1]) - 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.encoder.append(nn.ReLU())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.decoder = nn.ModuleList()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for i, (d_in, d_out) in enumerate(zip(self.dec_dims[:-1], self.dec_dims[1:])):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.decoder.append(nn.Linear(d_in, d_out))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if i != len(self.dec_dims[:-1]) - 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.decoder.append(nn.ReLU())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, rating_matrix, return_latent=False):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Forward pass with option to return latent variables\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Args:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            rating_matrix: Input rating matrix\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return_latent: If True, returns reconstruction, mean and logvar. If False, returns only reconstruction\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Encoder forward pass\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if len(rating_matrix.shape) == 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            rating_matrix = torch.unsqueeze(rating_matrix, 0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        h = F.dropout(F.normalize(rating_matrix, dim=-1), p=self.dropout, training=self.training)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.encoder:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            h = layer(h)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Sample from latent space\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        mu_q = h[:, :self.enc_dims[-1]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        logvar_q = h[:, self.enc_dims[-1]:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        std_q = torch.exp(0.5 * logvar_q)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        epsilon = torch.zeros_like(std_q).normal_(mean=0, std=1.0)  # Changed std to 1.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sampled_z = mu_q + self.training * epsilon * std_q\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        output = sampled_z\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.decoder:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            output = layer(output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            kl_loss = ((0.5 * (-logvar_q + torch.exp(logvar_q) + torch.pow(mu_q, 2) - 1)).sum(1)).mean()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return self.softmax(output), kl_loss, mu_q, std_q  # Return consistent outputs\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if self.demographic:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                return self.softmax(output[:,:self.items_only])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return self.softmax(output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def train_one_epoch(self, dataset, optimizer, batch_size, alpha=0.5):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Train model for one epoch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.train()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        train_matrix = dataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_training = train_matrix.shape[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_batches = int(np.ceil(num_training / batch_size))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        perm = np.random.permutation(num_training)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        loss = 0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for b in range(num_batches):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            optimizer.zero_grad()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if (b + 1) * batch_size >= num_training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_idx = perm[b * batch_size:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_idx = perm[b * batch_size: (b + 1) * batch_size]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            batch_matrix = torch.FloatTensor(train_matrix[batch_idx]).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if self.total_anneal_steps > 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.anneal = min(self.anneal_cap, 1. * self.update_count / self.total_anneal_steps)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.anneal = self.anneal_cap\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Get reconstructions, mean, and logvar from forward pass\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            pred_matrix, mu_q, logvar_q = self.forward(batch_matrix, return_latent=True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Calculate losses\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Cross entropy loss\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            total_ce = -(F.log_softmax(pred_matrix, 1) * batch_matrix)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            ce_hist = total_ce[:,:self.num_items].sum(1).mean()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            ce_demo = total_ce[:,self.num_items:].sum(1).mean() if self.demographic else 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            ce_loss = ce_hist + alpha * ce_demo\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # KL divergence loss\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            kl_loss = ((0.5 * (-logvar_q + torch.exp(logvar_q) + torch.pow(mu_q, 2) - 1)).sum(1)).mean()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Total loss\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            batch_loss = ce_loss + kl_loss * self.anneal\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            batch_loss.backward()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            optimizer.step()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.update_count += 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            loss += batch_loss\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if b \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m 200 == 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                print(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m%3d\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m%3d\u001b[39;00m\u001b[38;5;124m) loss = \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m (b, num_batches, batch_loss))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return loss\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def predict(self, eval_users, test_batch_size):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Predict the model on test set\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :param eval_users: evaluation (test) user\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :param eval_pos: position of the evaluated (test) item\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :param test_batch_size: batch size for test set\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        :return: predictions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with torch.no_grad():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            input_matrix = torch.Tensor(eval_users).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            preds = np.zeros_like(input_matrix.cpu())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            num_data = input_matrix.shape[0]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            num_batches = int(np.ceil(num_data / test_batch_size))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            perm = list(range(num_data))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for b in range(num_batches):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                if (b + 1) * test_batch_size >= num_data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    batch_idx = perm[b * test_batch_size:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    batch_idx = perm[b * test_batch_size: (b + 1) * test_batch_size]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                test_batch_matrix = input_matrix[batch_idx]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_pred_matrix = self.forward(test_batch_matrix)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_pred_matrix = batch_pred_matrix.masked_fill(test_batch_matrix.bool(), float(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                preds[batch_idx] = batch_pred_matrix.detach().cpu().numpy()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return preds\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m    ]\n\u001b[1;32m    248\u001b[0m   },\n\u001b[1;32m    249\u001b[0m   {\n\u001b[1;32m    250\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    251\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md20b4920-c062-47ac-ba14-0851f8386d5a\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    252\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    253\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnhanced VAE Recommender with Dynamic Epoch Selection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m    ]\n\u001b[1;32m    256\u001b[0m   },\n\u001b[1;32m    257\u001b[0m   {\n\u001b[1;32m    258\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    259\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    260\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7fd280be-5384-4636-b490-646a57fa0315\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    261\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    262\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    263\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn as nn\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch.nn.functional as F\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass EnhancedVAE(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, model_conf, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super(EnhancedVAE, self).__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_features = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_items = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.demographic = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemographic\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.demographic:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.num_items = num_features\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.items_only = num_items\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.num_items = num_items\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.enc_dims = [self.num_items] + model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menc_dims\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dec_dims = self.enc_dims[::-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dims = self.enc_dims + self.dec_dims[1:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.softmax = nn.Softmax(dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Training configuration\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.total_anneal_steps = model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_anneal_steps\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.anneal_cap = model_conf[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manneal_cap\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.eps = 1e-6\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.anneal = 0.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.update_count = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Early stopping configuration\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.patience = model_conf.get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, 5)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.min_delta = model_conf.get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_delta\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, 0.001)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.performance_threshold = model_conf.get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperformance_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, 0.20)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Initialize encoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.encoder = nn.ModuleList()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for i, (d_in, d_out) in enumerate(zip(self.enc_dims[:-1], self.enc_dims[1:])):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if i == len(self.enc_dims[:-1]) - 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                d_out *= 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.encoder.append(nn.Linear(d_in, d_out))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if i != len(self.enc_dims[:-1]) - 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.encoder.append(nn.ReLU())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Initialize decoder\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.decoder = nn.ModuleList()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for i, (d_in, d_out) in enumerate(zip(self.dec_dims[:-1], self.dec_dims[1:])):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.decoder.append(nn.Linear(d_in, d_out))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if i != len(self.dec_dims[:-1]) - 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.decoder.append(nn.ReLU())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, rating_matrix):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Encoder forward pass\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if len(rating_matrix.shape) == 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            rating_matrix = torch.unsqueeze(rating_matrix, 0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        h = F.dropout(F.normalize(rating_matrix, dim=-1), p=self.dropout, training=self.training)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.encoder:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            h = layer(h)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Sample from latent space\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        mu_q = h[:, :self.enc_dims[-1]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        logvar_q = h[:, self.enc_dims[-1]:]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        std_q = torch.exp(0.5 * logvar_q)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        epsilon = torch.zeros_like(std_q).normal_(mean=0, std=0.01)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sampled_z = mu_q + self.training * epsilon * std_q\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Decoder forward pass\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        output = sampled_z\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for layer in self.decoder:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            output = layer(output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            kl_loss = ((0.5 * (-logvar_q + torch.exp(logvar_q) + torch.pow(mu_q, 2) - 1)).sum(1)).mean()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return output, kl_loss\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if self.demographic:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                return self.softmax(output[:,:self.items_only])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                return self.softmax(output)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def train_with_dynamic_epochs(self, train_data, valid_data, optimizer, batch_size, max_epochs=100, alpha=0.5):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Train the model with dynamic epoch selection based on performance criteria\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        best_metric = float(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        patience_counter = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        best_epoch = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        training_history = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for epoch in range(max_epochs):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Train for one epoch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            train_loss = self.train_one_epoch(train_data, optimizer, batch_size, alpha)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Evaluate on validation set\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            hr10, hr50, hr100, mrr, mpr = self.evaluate(valid_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            current_metric = hr10  # Using HR@10 as primary metric\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Store training history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            training_history.append(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: epoch,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: train_loss,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr10\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: hr10,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr50\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: hr50,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr100\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: hr100,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmrr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: mrr,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmpr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: mpr\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            })\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Check if performance meets threshold criteria\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if current_metric > best_metric + self.min_delta:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                best_metric = current_metric\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                best_epoch = epoch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                patience_counter = 0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                # Save best model state\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                best_model_state = self.state_dict()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                patience_counter += 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Early stopping checks\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if patience_counter >= self.patience:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                break\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Performance threshold check\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if current_metric >= self.performance_threshold:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                break\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{epoch}\u001b[39;00m\u001b[38;5;124m: HR@10 = \u001b[39m\u001b[38;5;132;01m{hr10:.4f}\u001b[39;00m\u001b[38;5;124m, Loss = \u001b[39m\u001b[38;5;132;01m{train_loss:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Restore best model state\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.load_state_dict(best_model_state)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return best_epoch, training_history\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def evaluate(self, eval_data, batch_size=128):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        Evaluate the model on validation/test data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.eval()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with torch.no_grad():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Implement evaluation metrics calculation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            hr10, hr50, hr100, mrr, mpr = 0.0, 0.0, 0.0, 0.0, 0.0\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            num_users = len(eval_data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for i in range(0, num_users, batch_size):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_users = eval_data[i:min(i + batch_size, num_users)]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_predictions = self.forward(torch.Tensor(batch_users).to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                # Calculate metrics for batch\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_hr10 = self.calculate_hit_ratio(batch_predictions, k=10)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_hr50 = self.calculate_hit_ratio(batch_predictions, k=50)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_hr100 = self.calculate_hit_ratio(batch_predictions, k=100)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_mrr = self.calculate_mrr(batch_predictions)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                batch_mpr = self.calculate_mpr(batch_predictions)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                # Accumulate metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                hr10 += batch_hr10\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                hr50 += batch_hr50\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                hr100 += batch_hr100\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                mrr += batch_mrr\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                mpr += batch_mpr\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Average metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            hr10 /= num_users\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            hr50 /= num_users\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            hr100 /= num_users\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mrr /= num_users\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            mpr /= num_users\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return hr10, hr50, hr100, mrr, mpr\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def calculate_hit_ratio(self, predictions, k):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCalculate Hit Ratio @ k\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        _, top_k = torch.topk(predictions, k, dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return float(torch.any(top_k == self.target_items.unsqueeze(1), dim=1).float().mean())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def calculate_mrr(self, predictions):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCalculate Mean Reciprocal Rank\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        ranks = torch.argmax(predictions == self.target_items.unsqueeze(1), dim=1).float() + 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return float((1.0 / ranks).mean())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def calculate_mpr(self, predictions):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mCalculate Mean Percentile Rank\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        ranks = torch.argmax(predictions == self.target_items.unsqueeze(1), dim=1).float() + 1\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return float((ranks / predictions.size(1)).mean())\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m    ]\n\u001b[1;32m    454\u001b[0m   },\n\u001b[1;32m    455\u001b[0m   {\n\u001b[1;32m    456\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    457\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m51e79158\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    459\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# 4. NCF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m    ]\n\u001b[1;32m    462\u001b[0m   },\n\u001b[1;32m    463\u001b[0m   {\n\u001b[1;32m    464\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    465\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    466\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m427f6d41\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    467\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    468\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    469\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass GMF_model(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, hidden_size=8, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super(GMF_model, self).__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_user_GMF = nn.Linear(user_size, hidden_size, bias = False).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_item_GMF = nn.Linear(item_size, hidden_size, bias = False).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.predict_layer = nn.Linear(hidden_size, 1, bias = True).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.sigmoid = nn.Sigmoid()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, user_tensor, item_tensor):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_vec = self.embed_user_GMF(user_tensor.to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_vec = self.embed_item_GMF(item_tensor.to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if user_vec.shape!=item_vec.shape:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            user_res = torch.zeros(item_vec.shape).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            user_res[:] = user_vec\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            user_vec = user_res\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        output = self.predict_layer(torch.mul(user_vec, item_vec))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.sigmoid(output)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m    ]\n\u001b[1;32m    493\u001b[0m   },\n\u001b[1;32m    494\u001b[0m   {\n\u001b[1;32m    495\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    496\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m    497\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6a7950c8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    498\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    499\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    500\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MLP_model(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, hidden_size, num_layers, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super(MLP_model, self).__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        factor_num = hidden_size\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_user_MLP = nn.Linear(user_size, factor_num * (2 ** (num_layers - 1)), bias = False).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_item_MLP = nn.Linear(item_size, factor_num * (2 ** (num_layers - 1)), bias = False).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        MLP_modules = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for i in range(num_layers):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            input_size = factor_num * (2 ** (num_layers - i))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            MLP_modules.append(nn.Dropout(p=0.5))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            MLP_modules.append(nn.Linear(input_size, input_size//2).to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            MLP_modules.append(nn.ReLU())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.MLP_layers = nn.Sequential(*MLP_modules)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.predict_layer = nn.Linear(hidden_size, 1, bias = True).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.sigmoid = nn.Sigmoid()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, user_tensor, item_tensor):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        embed_user_MLP = self.embed_user_MLP(user_tensor.to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        embed_item_MLP = self.embed_item_MLP(item_tensor.to(self.device))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if embed_user_MLP.shape!=embed_item_MLP.shape:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            user_res = torch.zeros(embed_item_MLP.shape).to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            user_res[:] = embed_user_MLP\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            embed_user_MLP = user_res\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        output_MLP = self.MLP_layers(interaction)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        output = self.predict_layer(output_MLP)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return self.sigmoid(output)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m    ]\n\u001b[1;32m    534\u001b[0m   },\n\u001b[1;32m    535\u001b[0m   {\n\u001b[1;32m    536\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    537\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m7\u001b[39m,\n\u001b[1;32m    538\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m525f036a\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    539\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    540\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m    541\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass NCF(nn.Module):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def __init__(self, factor_num, num_layers,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    dropout, model, GMF_model=None, MLP_model=None, **kw):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        super(NCF, self).__init__()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_num: number of users;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_num: number of items;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        factor_num: number of predictive factors;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        num_layers: the number of layers in MLP model;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        dropout: dropout rate between fully connected layers;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        model: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGMF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeuMF-end\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeuMF-pre\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        GMF_model: pre-trained GMF weights;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        MLP_model: pre-trained MLP weights.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.dropout = dropout\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.model = model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.GMF_model = GMF_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.MLP_model = MLP_model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.device = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item_size = kw[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_items\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_user_GMF = nn.Linear(user_size, factor_num, bias = False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_item_GMF = nn.Linear(item_size, factor_num, bias = False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_user_MLP = nn.Linear(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                user_size, factor_num * (2 ** (num_layers - 1)), bias = False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.embed_item_MLP = nn.Linear(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                item_size, factor_num * (2 ** (num_layers - 1)), bias = False)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        MLP_modules = []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for i in range(num_layers):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            input_size = factor_num * (2 ** (num_layers - i))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            MLP_modules.append(nn.Dropout(p=self.dropout))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            MLP_modules.append(nn.Linear(input_size, input_size//2))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            MLP_modules.append(nn.ReLU())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.MLP_layers = nn.Sequential(*MLP_modules)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.model in [\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGMF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            predict_size = factor_num \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            predict_size = factor_num * 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.predict_layer = nn.Linear(predict_size, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.sigmoid = nn.Sigmoid()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self._init_weight_()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Move the entire model to the specified device\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        self.to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def _init_weight_(self):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m We leave the weights initialization here. \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if not self.model == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeuMF-pre\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            nn.init.normal_(self.embed_user_GMF.weight, std=0.01)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            nn.init.normal_(self.embed_user_MLP.weight, std=0.01)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            nn.init.normal_(self.embed_item_GMF.weight, std=0.01)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            nn.init.normal_(self.embed_item_MLP.weight, std=0.01)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for m in self.MLP_layers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                if isinstance(m, nn.Linear):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    nn.init.xavier_uniform_(m.weight)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            nn.init.kaiming_uniform_(self.predict_layer.weight, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                                    a=1, nonlinearity=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for m in self.modules():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                if isinstance(m, nn.Linear) and m.bias is not None:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    m.bias.data.zero_()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # embedding layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.embed_user_GMF.weight.data.copy_(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                            self.GMF_model.embed_user_GMF.weight)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.embed_item_GMF.weight.data.copy_(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                            self.GMF_model.embed_item_GMF.weight)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.embed_user_MLP.weight.data.copy_(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                            self.MLP_model.embed_user_MLP.weight)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.embed_item_MLP.weight.data.copy_(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                            self.MLP_model.embed_item_MLP.weight)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # mlp layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            for (m1, m2) in zip(\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.MLP_layers, self.MLP_model.MLP_layers):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                if isinstance(m1, nn.Linear) and isinstance(m2, nn.Linear):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    m1.weight.data.copy_(m2.weight)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    m1.bias.data.copy_(m2.bias)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # predict layers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            predict_weight = torch.cat([\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.GMF_model.predict_layer.weight, \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                self.MLP_model.predict_layer.weight], dim=1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            precit_bias = self.GMF_model.predict_layer.bias + \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                        self.MLP_model.predict_layer.bias\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.predict_layer.weight.data.copy_(0.5 * predict_weight)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            self.predict_layer.bias.data.copy_(0.5 * precit_bias)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def forward(self, user, item):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        user = user.to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        item = item.to(self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if not self.model == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            embed_user_GMF = self.embed_user_GMF(user)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            embed_item_GMF = self.embed_item_GMF(item)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if embed_user_GMF.shape!=embed_item_GMF.shape:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                user_res = torch.zeros(embed_item_GMF.shape, device=self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                user_res[:] = embed_user_GMF\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                embed_user_GMF = user_res\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            output_GMF = embed_user_GMF * embed_item_GMF\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if not self.model == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGMF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            embed_user_MLP = self.embed_user_MLP(user)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            embed_item_MLP = self.embed_item_MLP(item)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if embed_user_MLP.shape!=embed_item_MLP.shape:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                user_res = torch.zeros(embed_item_MLP.shape, device=self.device)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                user_res[:] = embed_user_MLP\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                embed_user_MLP = user_res\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            interaction = torch.cat((embed_user_MLP, embed_item_MLP), -1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            output_MLP = self.MLP_layers(interaction)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if self.model == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGMF\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            concat = output_GMF\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        elif self.model == \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            concat = output_MLP\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            concat = torch.cat((output_GMF, output_MLP), -1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        prediction = self.predict_layer(concat)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        prediction = self.sigmoid(prediction)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return prediction.view(-1)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    666\u001b[0m    ]\n\u001b[1;32m    667\u001b[0m   }\n\u001b[1;32m    668\u001b[0m  ],\n\u001b[1;32m    669\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    670\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    671\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython 3 (ipykernel)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    672\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    673\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    674\u001b[0m   },\n\u001b[1;32m    675\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    676\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    679\u001b[0m    },\n\u001b[1;32m    680\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    681\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    682\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    683\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    684\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    685\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.12.4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m   },\n\u001b[1;32m    687\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoc\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    688\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_numbering\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    689\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnav_menu\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    690\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_sections\u001b[39m\u001b[38;5;124m\"\u001b[39m: true,\n\u001b[1;32m    691\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msideBar\u001b[39m\u001b[38;5;124m\"\u001b[39m: true,\n\u001b[1;32m    692\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_h1_title\u001b[39m\u001b[38;5;124m\"\u001b[39m: false,\n\u001b[1;32m    693\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_cell\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable of Contents\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    694\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle_sidebar\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContents\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    695\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoc_cell\u001b[39m\u001b[38;5;124m\"\u001b[39m: false,\n\u001b[1;32m    696\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoc_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m    697\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoc_section_display\u001b[39m\u001b[38;5;124m\"\u001b[39m: true,\n\u001b[1;32m    698\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoc_window_display\u001b[39m\u001b[38;5;124m\"\u001b[39m: false\n\u001b[1;32m    699\u001b[0m   }\n\u001b[1;32m    700\u001b[0m  },\n\u001b[1;32m    701\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    702\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m    703\u001b[0m }\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = load_recommender(data_name, hidden_dim, checkpoints_path, recommender_path, **kw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e57f7",
   "metadata": {},
   "source": [
    "## plot the distribution of top recommended item accross all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ceeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of top recommended item accross all users\n",
    "topk_train = {}\n",
    "for i in range(len(train_array)):\n",
    "    vec = train_array[i]\n",
    "    tens = torch.Tensor(vec).to(device)\n",
    "    topk_train[i] = int(get_user_recommended_item(tens, model).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(topk_train.values(), bins=1000)\n",
    "plt.plot(np.array(list(pop_dict.keys())), np.array(list(pop_dict.values()))*100, alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_test = {}\n",
    "for i in range(len(test_array)):\n",
    "    vec = test_array[i]\n",
    "    tens = torch.Tensor(vec).to(device)\n",
    "    topk_test[i] = int(get_user_recommended_item(tens, model).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(topk_test.values(), bins=400)\n",
    "plt.plot(np.array(list(pop_dict.keys())), np.array(list(pop_dict.values()))*200, alpha=0.2)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9637160",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_rate_at_10, hit_rate_at_50, hit_rate_at_100, MRR, MPR = recommender_evaluations(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ae07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hit_rate_at_10, hit_rate_at_50, hit_rate_at_100, MRR, MPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a2f7c-49c5-4dd7-98bb-03181af163f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
