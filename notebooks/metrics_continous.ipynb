{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d13187-d80e-482c-968b-a940a37a0fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "export_dir = os.getcwd()\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import optuna\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import ipynb\n",
    "import importlib\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e5c034-70a8-401a-92c9-ea21ab6821aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"ML1M\" ### Can be ML1M, Yahoo, Pinterest\n",
    "recommender_name = \"MLP\" ### Can be MLP, VAE, NCF\n",
    "\n",
    "DP_DIR = Path(\"processed_data\", data_name) \n",
    "export_dir = Path(os.getcwd())\n",
    "files_path = Path(\"/storage/mikhail/PI4Rec\", DP_DIR)\n",
    "checkpoints_path = Path(export_dir.parent, \"checkpoints\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7743e4a1-35a0-4433-bb93-7864998f0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type_dict = {\n",
    "    \"VAE\":\"multiple\",\n",
    "    \"MLP\":\"single\",\n",
    "    \"NCF\": \"single\"}\n",
    "\n",
    "num_users_dict = {\n",
    "    \"ML1M\":6037,\n",
    "    \"Yahoo\":13797, \n",
    "    \"Pinterest\":19155}\n",
    "\n",
    "num_items_dict = {\n",
    "    \"ML1M\":3381,\n",
    "    \"Yahoo\":4604, \n",
    "    \"Pinterest\":9362}\n",
    "\n",
    "\n",
    "recommender_path_dict = {\n",
    "    (\"ML1M\",\"VAE\"): Path(checkpoints_path, \"VAE_ML1M_0.0007_128_10.pt\"),\n",
    "    (\"ML1M\",\"MLP\"):Path(checkpoints_path, \"MLP1_ML1M_0.0076_256_7.pt\"),\n",
    "    (\"ML1M\",\"NCF\"):Path(checkpoints_path, \"NCF_ML1M_5e-05_64_16.pt\"),\n",
    "    \n",
    "    (\"Yahoo\",\"VAE\"): Path(checkpoints_path, \"VAE_Yahoo_0.0001_128_13.pt\"),\n",
    "    (\"Yahoo\",\"MLP\"):Path(checkpoints_path, \"MLP2_Yahoo_0.0083_128_1.pt\"),\n",
    "    (\"Yahoo\",\"NCF\"):Path(checkpoints_path, \"NCF_Yahoo_0.001_64_21_0.pt\"),\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): Path(checkpoints_path, \"VAE_Pinterest_12_18_0.0001_256.pt\"),\n",
    "    (\"Pinterest\",\"MLP\"):Path(checkpoints_path, \"MLP_Pinterest_0.0062_512_21_0.pt\"),\n",
    "    (\"Pinterest\",\"NCF\"):Path(checkpoints_path, \"NCF2_Pinterest_9e-05_32_9_10.pt\"),}\n",
    "\n",
    "\n",
    "hidden_dim_dict = {\n",
    "    (\"ML1M\",\"VAE\"): None,\n",
    "    (\"ML1M\",\"MLP\"): 32,\n",
    "    (\"ML1M\",\"NCF\"): 8,\n",
    "\n",
    "    (\"Yahoo\",\"VAE\"): None,\n",
    "    (\"Yahoo\",\"MLP\"):32,\n",
    "    (\"Yahoo\",\"NCF\"):8,\n",
    "    \n",
    "    (\"Pinterest\",\"VAE\"): None,\n",
    "    (\"Pinterest\",\"MLP\"):512,\n",
    "    (\"Pinterest\",\"NCF\"): 64,\n",
    "}\n",
    "LXR_checkpoint_dict = {\n",
    "    (\"ML1M\",\"VAE\"): ('LXR_ML1M_VAE_26_38_128_3.185652725834087_1.420642300151426.pt',128),\n",
    "    (\"ML1M\",\"MLP\"): ('LXR_ML1M_MLP_19_3_128_13.109692424872248_7.829643365925428.pt',128),\n",
    "    (\"Yahoo\",\"VAE\"): ('LXR_Yahoo_VAE_neg-1.5pos_combined_19_26_128_18.958765029913238_4.92235962483309.pt',128),\n",
    "    (\"Yahoo\",\"MLP\"):('LXR_Yahoo_MLP_neg-pos_combined_last_29_37_128_12.40692505393434_0.19367009952856118.pt',128),\n",
    "    (\"Pinterest\",\"VAE\"): ('LXR_Pinterest_VAE_0_18_64_3.669673618522336_1.7221734058804223.pt',64),\n",
    "    (\"Pinterest\",\"MLP\"):('LXR_Pinterest_MLP_0_5_16_10.059416809308486_0.705778173474644.pt',16),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3c2cf7-0df5-4b52-b94f-113eae5e466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_type = output_type_dict[recommender_name] ### Can be single, multiple\n",
    "num_users = num_users_dict[data_name] \n",
    "num_items = num_items_dict[data_name] \n",
    "\n",
    "hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "recommender_path = recommender_path_dict[(data_name,recommender_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1688d9-61e1-4d26-bb30-9d3a6aefe7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(Path(files_path,f'train_data_{data_name}.csv'), index_col=0)\n",
    "test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "static_test_data = pd.read_csv(Path(files_path,f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "with open(Path(files_path,f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f)\n",
    "train_array = train_data.to_numpy()\n",
    "test_array = test_data.to_numpy()\n",
    "items_array = np.eye(num_items)\n",
    "all_items_tensor = torch.Tensor(items_array).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9342008-cf3d-4057-83fc-7c8a9a239e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = static_test_data.iloc[:,:-2].to_numpy()\n",
    "with open(Path(files_path, f'jaccard_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    jaccard_dict = pickle.load(f) \n",
    "with open(Path(files_path, f'cosine_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "    cosine_dict = pickle.load(f) \n",
    "with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "    pop_dict = pickle.load(f) \n",
    "with open(Path(files_path, f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    item_to_cluster = pickle.load(f) \n",
    "with open(Path(files_path, f'shap_values_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "    shap_values= pickle.load(f) \n",
    "for i in range(num_items):\n",
    "    for j in range(i, num_items):\n",
    "        jaccard_dict[(j,i)]= jaccard_dict[(i,j)]\n",
    "        cosine_dict[(j,i)]= cosine_dict[(i,j)]\n",
    "        pop_array = np.zeros(len(pop_dict))\n",
    "for key, value in pop_dict.items():\n",
    "    pop_array[key] = value\n",
    "kw_dict = {\n",
    "    'device': device,\n",
    "    'num_items': num_items,\n",
    "    'num_features': num_items,\n",
    "    'pop_array': pop_array,\n",
    "    'all_items_tensor': all_items_tensor,\n",
    "    'static_test_data': static_test_data,\n",
    "    'items_array': items_array,\n",
    "    'output_type': output_type,\n",
    "    'recommender_name': recommender_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f822bcf-fe8c-47c9-9952-d190dd5d72aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/mikhail/PI4Rec/code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "#os.chdir('/storage/mikhail/PI4Rec/code')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fda75b-849d-4a71-81b1-e4ed749e3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../baselines') \n",
    "from ipynb.fs.defs.help_functions import recommender_run\n",
    "from ipynb.fs.defs.lime import *\n",
    "from ipynb.fs.defs.lime import *\n",
    "importlib.reload(ipynb.fs.defs.lime)\n",
    "from ipynb.fs.defs.lime import *\n",
    "lime = LimeBase(distance_to_proximity)\n",
    "\n",
    "\n",
    "\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "importlib.reload(ipynb.fs.defs.help_functions)\n",
    "from ipynb.fs.defs.help_functions import *\n",
    "\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "importlib.reload(ipynb.fs.defs.recommenders_architecture)\n",
    "from ipynb.fs.defs.recommenders_architecture import *\n",
    "\n",
    "VAE_config= {\n",
    "\"enc_dims\": [512,128],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}\n",
    "\n",
    "\n",
    "Pinterest_VAE_config= {\n",
    "\"enc_dims\": [256,64],\n",
    "\"dropout\": 0.5,\n",
    "\"anneal_cap\": 0.2,\n",
    "\"total_anneal_steps\": 200000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d792be-019e-4eeb-8973-255a46e7aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explainer(nn.Module):\n",
    "    def __init__(self, user_size, item_size, hidden_size):\n",
    "        super(Explainer, self).__init__()\n",
    "        \n",
    "        self.users_fc = nn.Linear(in_features = user_size, out_features=hidden_size).to(device)\n",
    "        self.items_fc = nn.Linear(in_features = item_size, out_features=hidden_size).to(device)\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size*2, out_features=hidden_size).to(device),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features = hidden_size, out_features=user_size).to(device),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        \n",
    "    def forward(self, user_tensor, item_tensor):\n",
    "        user_output = self.users_fc(user_tensor.float())\n",
    "        item_output = self.items_fc(item_tensor.float())\n",
    "        combined_output = torch.cat((user_output, item_output), dim=-1)\n",
    "        expl_scores = self.bottleneck(combined_output).to(device)\n",
    "        return expl_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df5e5749-b94b-44b0-b58f-76158bc126a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_explainer(fine_tuning=False, lambda_pos=None, lambda_neg=None, alpha=None):\n",
    "    lxr_path, lxr_dim = LXR_checkpoint_dict[(data_name, recommender_name)]\n",
    "    explainer = Explainer(num_items, num_items, lxr_dim)\n",
    "    lxr_checkpoint = torch.load(Path(checkpoints_path, lxr_path))\n",
    "    explainer.load_state_dict(lxr_checkpoint)\n",
    "    explainer.eval()\n",
    "    for param in explainer.parameters():\n",
    "        param.requires_grad = False\n",
    "    return explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71481488-7a02-4491-8fe0-44bff4ff114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LXR explainer...\n",
      "LXR explainer loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def load_recommender():\n",
    "    if recommender_name == 'MLP':\n",
    "        recommender = MLP(hidden_dim, **kw_dict)\n",
    "    elif recommender_name == 'VAE':\n",
    "        if data_name == \"Pinterest\":\n",
    "            recommender = VAE(Pinterest_VAE_config, **kw_dict)\n",
    "        else:\n",
    "            recommender = VAE(VAE_config, **kw_dict)\n",
    "    elif recommender_name == 'NCF':\n",
    "        MLP_temp = MLP_model(hidden_size=hidden_dim, num_layers=3, **kw_dict)\n",
    "        GMF_temp = GMF_model(hidden_size=hidden_dim, **kw_dict)\n",
    "        recommender = NCF(factor_num=hidden_dim, num_layers=3, dropout=0.5, model='NeuMF-pre', GMF_model=GMF_temp, MLP_model=MLP_temp, **kw_dict)\n",
    "\n",
    "    # Check if the model's state_dict matches the architecture\n",
    "    recommender_checkpoint = torch.load(recommender_path, map_location=device)\n",
    "    recommender.load_state_dict(recommender_checkpoint, strict=False)\n",
    "    recommender.eval()\n",
    "    for param in recommender.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Debug print to verify model parameters\n",
    "    #print(f\"Model {recommender_name} initialized with parameters: {list(recommender.parameters())[:5]}\")\n",
    "    \n",
    "    return recommender\n",
    "recommender = load_recommender()\n",
    "\n",
    "# Загружаем explainer глобально\n",
    "print(\"Loading LXR explainer...\")\n",
    "explainer = load_explainer()\n",
    "print(\"LXR explainer loaded successfully\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ede02658-6ced-4dd1-b2d0-c94aacfa2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pop_mask(x, item_id):\n",
    "    user_hist = torch.Tensor(x).to(device) # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_pop_dict = {}\n",
    "    \n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            item_pop_dict[i]=pop_array[i] # add the pop of the item to the dictionary\n",
    "            \n",
    "    return item_pop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46eddb52-a66a-4fd4-929a-5622c0264b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User based similarities using Jaccard\n",
    "def find_jaccard_mask(x, item_id, user_based_Jaccard_sim):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_jaccard_dict = {}\n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            if (i,item_id) in user_based_Jaccard_sim:\n",
    "                item_jaccard_dict[i]=user_based_Jaccard_sim[(i,item_id)] # add Jaccard similarity between items\n",
    "            else:\n",
    "                item_jaccard_dict[i] = 0            \n",
    "\n",
    "    return item_jaccard_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c57942e-ce2c-47ba-900c-77cd7906e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine based similarities between users and items\n",
    "def find_cosine_mask(x, item_id, item_cosine):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    item_cosine_dict = {}\n",
    "    for i,j in enumerate(user_hist>0):\n",
    "        if j:\n",
    "            if (i,item_id) in item_cosine:\n",
    "                item_cosine_dict[i]=item_cosine[(i,item_id)]\n",
    "            else:\n",
    "                item_cosine_dict[i]=0\n",
    "\n",
    "    return item_cosine_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c8a6f-de19-4e0d-8f03-f49c05f06120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35ecf88b-e353-436a-bf6e-14b70c7e4560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lxr_mask(x, item_tensor):\n",
    "    user_hist = x\n",
    "    expl_scores = explainer(user_hist, item_tensor)\n",
    "    x_masked = user_hist * expl_scores\n",
    "    item_sim_dict = {}\n",
    "    for i, j in enumerate(x_masked > 0):\n",
    "        if j:\n",
    "            item_sim_dict[i] = x_masked[i] \n",
    "    return item_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23814019-635a-47a3-8024-91422268e698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b3884e0-32fc-4aea-a6d6-921d5cd862dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lime_mask(x, item_id, min_pert, max_pert, num_of_perturbations, kernel_func, feature_selection, recommender, num_samples=10, method = 'POS', **kw_dict):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    lime.kernel_fn = kernel_func\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lime_args(user_hist, item_id, recommender, all_items_tensor, min_pert = min_pert, max_pert = max_pert, num_of_perturbations = num_of_perturbations, seed = item_id, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection, pos_neg='POS')\n",
    "    if method=='NEG':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_samples, feature_selection ,pos_neg='NEG')\n",
    "        \n",
    "    return most_pop_items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6d96b0b-c479-4f15-ab5a-ca6e0c8df383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lire_mask(x, item_id, num_of_perturbations, kernel_func, feature_selection, recommender, proba=0.1, method = 'POS', **kw_dict):\n",
    "    user_hist = x # remove the positive item we want to explain from the user history\n",
    "    user_hist[item_id] = 0\n",
    "    lime.kernel_fn = kernel_func\n",
    "\n",
    "    neighborhood_data, neighborhood_labels, distances, item_id = get_lire_args(user_hist, item_id, recommender, all_items_tensor, train_array, num_of_perturbations = num_of_perturbations, seed = item_id, proba=0.1, **kw_dict)\n",
    "    if method=='POS':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_of_perturbations, feature_selection, pos_neg='POS')\n",
    "    if method=='NEG':\n",
    "        most_pop_items  = lime.explain_instance_with_data(neighborhood_data, neighborhood_labels, distances, item_id, num_of_perturbations, feature_selection ,pos_neg='NEG')\n",
    "        \n",
    "    return most_pop_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c69a9ca0-b6cd-4171-a63e-5e516af77ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fia_mask(user_tensor, item_tensor, item_id, recommender):\n",
    "    y_pred = recommender_run(user_tensor, recommender, item_tensor, item_id, **kw_dict).to(device)\n",
    "    items_fia = {}\n",
    "    user_hist = user_tensor.cpu().detach().numpy().astype(int)\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        if(user_hist[i] == 1):\n",
    "            user_hist[i] = 0\n",
    "            user_tensor = torch.FloatTensor(user_hist).to(device)\n",
    "            y_pred_without_item = recommender_run(user_tensor, recommender, item_tensor, item_id, 'single', **kw_dict).to(device)\n",
    "            infl_score = y_pred - y_pred_without_item\n",
    "            items_fia[i] = infl_score\n",
    "            user_hist[i] = 1\n",
    "\n",
    "    return items_fia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6fe48a9-c488-488d-ba29-091c3d6b92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shapley_mask(user_tensor, user_id, model, shap_values, item_to_cluster):\n",
    "    item_shap = {}\n",
    "    shapley_values = shap_values[shap_values[:, 0].astype(int) == user_id][:,1:]\n",
    "    user_vector = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    for i in np.where(user_vector.astype(int) == 1)[0]:\n",
    "        items_cluster = item_to_cluster[i]\n",
    "        item_shap[i] = shapley_values.T[int(items_cluster)][0]\n",
    "\n",
    "    return item_shap  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ffa351-22c2-426b-a5be-f87efdffa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, top_k):\n",
    "   \n",
    "    items_accent = defaultdict(float)\n",
    "    factor = top_k - 1\n",
    "    user_accent_hist = user_tensor.cpu().detach().numpy().astype(int)\n",
    "\n",
    "    #Get topk items\n",
    "    sorted_indices = list(get_top_k(user_tensor, user_tensor, recommender_model, **kw_dict).keys())\n",
    "    \n",
    "    if top_k == 1:\n",
    "        # When k=1, return the index of the first maximum value\n",
    "        top_k_indices = [sorted_indices[0]]\n",
    "    else:\n",
    "        top_k_indices = sorted_indices[:top_k]\n",
    "   \n",
    "\n",
    "    for iteration, item_k_id in enumerate(top_k_indices):\n",
    "\n",
    "        # Set topk items to 0 in the user's history\n",
    "        user_accent_hist[item_k_id] = 0\n",
    "        user_tensor = torch.FloatTensor(user_accent_hist).to(device)\n",
    "       \n",
    "        item_vector = items_array[item_k_id]\n",
    "        item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "              \n",
    "        # Check influence of the items in the history on this specific item in topk\n",
    "        fia_dict = find_fia_mask(user_tensor, item_tensor, item_k_id, recommender_model)\n",
    "         \n",
    "        # Sum up all differences between influence on top1 and other topk values\n",
    "        if not iteration:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] *= factor\n",
    "        else:\n",
    "            for key in fia_dict.keys():\n",
    "                items_accent[key] -= fia_dict[key]\n",
    "       \n",
    "    for key in items_accent.keys():\n",
    "        items_accent[key] *= -1    \n",
    "\n",
    "    return items_accent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e85c73d-f81c-42c3-874f-99fd49065e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender_model, user_id = None, mask_type = None):\n",
    "    '''\n",
    "    This function invokes various explanation functions\n",
    "    and returns a dictionary of explanations, sorted by their scores.\n",
    "    '''\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "\n",
    "    if mask_type == 'lime':\n",
    "        POS_sim_items = find_lime_mask(user_vector, item_id, 50, 100, 150, distance_to_proximity, 'highest_weights', recommender_model, num_samples=user_hist_size, **kw_dict)\n",
    "        NEG_sim_items = find_lime_mask(user_vector, item_id, 50, 100, 150, distance_to_proximity, 'highest_weights', recommender_model, num_samples=user_hist_size, method='NEG', **kw_dict)\n",
    "    else:\n",
    "        if mask_type == 'jaccard':\n",
    "            sim_items = find_jaccard_mask(user_tensor, item_id, jaccard_dict)\n",
    "        elif mask_type == 'cosine':\n",
    "            sim_items = find_cosine_mask(user_tensor, item_id, cosine_dict)\n",
    "        elif mask_type == 'shap':\n",
    "            sim_items = find_shapley_mask(user_tensor, user_id, recommender_model, shap_values, item_to_cluster)\n",
    "        elif mask_type == 'accent':\n",
    "            sim_items = find_accent_mask(user_tensor, user_id, item_tensor, item_id, recommender_model, 5)\n",
    "        elif mask_type == 'lxr':\n",
    "            sim_items = find_lxr_mask(user_tensor, item_tensor)  # Теперь просто вызываем функцию\n",
    "        \n",
    "        POS_sim_items = list(sorted(sim_items.items(), key=lambda item: item[1], reverse=True))[0:user_hist_size]\n",
    "    \n",
    "    return POS_sim_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e54714f-3733-49a6-a2c1-eef605495be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsBaselines:\n",
    "    def __init__(self, data_name, recommender_name):\n",
    "        self.data_name = data_name\n",
    "        self.recommender_name = recommender_name\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.setup_data_and_recommender()\n",
    "\n",
    "    def setup_data_and_recommender(self):\n",
    "        # Set up all necessary data and variables\n",
    "        DP_DIR = Path(\"processed_data\", self.data_name)\n",
    "        self.files_path = Path(export_dir.parent, DP_DIR)\n",
    "        self.num_users = num_users_dict[self.data_name]\n",
    "        self.num_items = num_items_dict[self.data_name]\n",
    "        \n",
    "        self.test_data = pd.read_csv(Path(self.files_path, f'test_data_{self.data_name}.csv'), index_col=0)\n",
    "        self.test_array = self.test_data.to_numpy()\n",
    "        self.items_array = np.eye(self.num_items)\n",
    "        \n",
    "        with open(Path(self.files_path, f'pop_dict_{self.data_name}.pkl'), 'rb') as f:\n",
    "            self.pop_dict = pickle.load(f)\n",
    "        \n",
    "        # Load other necessary data (jaccard_dict, cosine_dict, item_to_cluster, shap_values)\n",
    "        \n",
    "        self.kw_dict = {\n",
    "            'device': self.device,\n",
    "            'num_items': self.num_items,\n",
    "            'num_features': self.num_items,\n",
    "            'demographic': False,\n",
    "            'pop_array': np.array([self.pop_dict.get(i, 0) for i in range(self.num_items)]),\n",
    "            'all_items_tensor': torch.eye(self.num_items).to(self.device),\n",
    "            'static_test_data': self.test_data,\n",
    "            'items_array': self.items_array,\n",
    "            'output_type': output_type_dict[self.recommender_name],\n",
    "            'recommender_name': self.recommender_name,\n",
    "            'files_path': self.files_path\n",
    "        }\n",
    "        \n",
    "        self.recommender = self.load_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80af0804-97c7-40ce-b7b3-e716d98d4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user(user_index, test_array, test_data, recommender, kw_dict):\n",
    "    try:\n",
    "        user_vector = test_array[user_index]\n",
    "        user_tensor = torch.FloatTensor(user_vector).to(kw_dict['device'])\n",
    "        user_id = int(test_data.index[user_index])\n",
    "\n",
    "        item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "        item_vector = kw_dict['items_array'][item_id]\n",
    "        item_tensor = torch.FloatTensor(item_vector).to(kw_dict['device'])\n",
    "\n",
    "        user_vector[item_id] = 0\n",
    "        user_tensor[item_id] = 0\n",
    "\n",
    "        results = {}\n",
    "        for method in ['pop', 'jaccard', 'cosine', 'lime', 'lxr', 'accent', 'shap']:\n",
    "            results[method] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, kw_dict['num_items'], recommender, mask_type=method, user_id=user_id if method == 'shap' else None)\n",
    "\n",
    "        return user_id, results\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing user {user_id}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72016e49-dfc1-4161-98fd-2a2859c01edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender_model, expl_dict, **kw_dict):\n",
    "    '''\n",
    "    This function takes the explanation dictionary as input.\n",
    "    It iteratively removes items from the user's history based on their explanation scores\n",
    "    and calculates metrics for the resulting counterfactual user vector.\n",
    "    '''\n",
    "    POS_masked = user_tensor\n",
    "    NEG_masked = user_tensor\n",
    "    POS_masked[item_id] = 0\n",
    "    NEG_masked[item_id] = 0\n",
    "    user_hist_size = np.sum(user_vector)\n",
    "    \n",
    "    bins = [0] + [len(x) for x in np.array_split(np.arange(user_hist_size), num_of_bins, axis=0)]\n",
    "    \n",
    "    # Initialize arrays for both POS and NEG metrics\n",
    "    POS_at_1 = [0] * (len(bins))\n",
    "    POS_at_5 = [0] * (len(bins))\n",
    "    POS_at_10 = [0] * (len(bins))\n",
    "    POS_at_20 = [0] * (len(bins))\n",
    "    \n",
    "    NEG_at_1 = [0] * (len(bins))\n",
    "    NEG_at_5 = [0] * (len(bins))\n",
    "    NEG_at_10 = [0] * (len(bins))\n",
    "    NEG_at_20 = [0] * (len(bins))\n",
    "    \n",
    "    DEL = [0] * (len(bins))\n",
    "    INS = [0] * (len(bins))\n",
    "    NDCG = [0] * (len(bins))\n",
    "    \n",
    "    POS_sim_items = expl_dict\n",
    "    NEG_sim_items = list(sorted(dict(POS_sim_items).items(), key=lambda item: item[1], reverse=False))\n",
    "    \n",
    "    total_items = 0\n",
    "    for i in range(len(bins)):\n",
    "        total_items += bins[i]\n",
    "        \n",
    "        # Process POS masks\n",
    "        POS_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        for j in POS_sim_items[:total_items]:\n",
    "            POS_masked[j[0]] = 1\n",
    "        POS_masked = user_tensor - POS_masked  # remove the masked items\n",
    "        \n",
    "        # Process NEG masks\n",
    "        NEG_masked = torch.zeros_like(user_tensor, dtype=torch.float32, device=device)\n",
    "        for j in NEG_sim_items[:total_items]:\n",
    "            NEG_masked[j[0]] = 1\n",
    "        NEG_masked = user_tensor - NEG_masked  # remove the masked items\n",
    "        \n",
    "        # Get rankings for both POS and NEG\n",
    "        POS_ranked_list = get_top_k(POS_masked, user_tensor, recommender_model, **kw_dict)\n",
    "        \n",
    "        if item_id in list(POS_ranked_list.keys()):\n",
    "            POS_index = list(POS_ranked_list.keys()).index(item_id) + 1\n",
    "        else:\n",
    "            POS_index = num_items\n",
    "        NEG_index = get_index_in_the_list(NEG_masked, user_tensor, item_id, recommender_model, **kw_dict) + 1\n",
    "        \n",
    "        # Calculate POS metrics\n",
    "        POS_at_1[i] = 1 if POS_index <= 1 else 0\n",
    "        POS_at_5[i] = 1 if POS_index <= 5 else 0\n",
    "        POS_at_10[i] = 1 if POS_index <= 10 else 0\n",
    "        POS_at_20[i] = 1 if POS_index <= 20 else 0\n",
    "        \n",
    "        # Calculate NEG metrics\n",
    "        NEG_at_1[i] = 1 if NEG_index <= 1 else 0\n",
    "        NEG_at_5[i] = 1 if NEG_index <= 5 else 0\n",
    "        NEG_at_10[i] = 1 if NEG_index <= 10 else 0\n",
    "        NEG_at_20[i] = 1 if NEG_index <= 20 else 0\n",
    "        \n",
    "        # Calculate other metrics\n",
    "        DEL[i] = float(recommender_run(POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "        INS[i] = float(recommender_run(user_tensor-POS_masked, recommender_model, item_tensor, item_id, **kw_dict).detach().cpu().numpy())\n",
    "        NDCG[i] = get_ndcg(list(POS_ranked_list.keys()), item_id, **kw_dict)\n",
    "    \n",
    "    res = [DEL, INS, NDCG, \n",
    "           POS_at_5, POS_at_10, POS_at_20,\n",
    "           NEG_at_5, NEG_at_10, NEG_at_20]\n",
    "    \n",
    "    for i in range(len(res)):\n",
    "        res[i] = np.array(res[i])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5014335c-4a98-4639-b404-337fe9864cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_one_expl_type(expl_name):\n",
    "    print(f' ============ Start explaining {data_name} {recommender_name} by {expl_name} ============')\n",
    "    \n",
    "    # Load the appropriate explanation dictionary\n",
    "    if expl_name == 'PI_base':\n",
    "        with open(Path(files_path, f'{recommender_name}_PI_base_expl_dict.pkl'), 'rb') as handle:\n",
    "            expl_dict = pickle.load(handle)\n",
    "    else:\n",
    "        with open(Path(files_path,f'{recommender_name}_{expl_name}_expl_dict.pkl'), 'rb') as handle:\n",
    "            expl_dict = pickle.load(handle)\n",
    "    \n",
    "    recommender.eval()\n",
    "    \n",
    "    num_of_bins = 10  # Fixed number of bins for all users\n",
    "    \n",
    "    # Initialize arrays for all metrics\n",
    "    metrics = {\n",
    "        'DEL': np.zeros(num_of_bins + 1),\n",
    "        'INS': np.zeros(num_of_bins + 1),\n",
    "        'NDCG': np.zeros(num_of_bins + 1),\n",
    "        'POS_at_5': np.zeros(num_of_bins + 1),\n",
    "        'POS_at_10': np.zeros(num_of_bins + 1),\n",
    "        'POS_at_20': np.zeros(num_of_bins + 1),\n",
    "        'NEG_at_5': np.zeros(num_of_bins + 1),\n",
    "        'NEG_at_10': np.zeros(num_of_bins + 1),\n",
    "        'NEG_at_20': np.zeros(num_of_bins + 1)\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(test_array.shape[0])):\n",
    "            user_vector = test_array[i]\n",
    "            user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "            user_id = int(test_data.index[i])\n",
    "\n",
    "            item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "            item_vector = items_array[item_id]\n",
    "            item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "            user_vector[item_id] = 0\n",
    "            user_tensor[item_id] = 0\n",
    "\n",
    "            user_expl = expl_dict[user_id]\n",
    "\n",
    "            res = single_user_metrics(user_vector, user_tensor, item_id, item_tensor, num_of_bins, recommender, user_expl, **kw_dict)\n",
    "            \n",
    "            # Ensure all arrays have the same length before adding\n",
    "            for j in range(len(res)):\n",
    "                if len(res[j]) != len(metrics['DEL']):\n",
    "                    res[j] = np.interp(np.linspace(0, 1, len(metrics['DEL'])), \n",
    "                                     np.linspace(0, 1, len(res[j])), \n",
    "                                     res[j])\n",
    "            \n",
    "            # Map results to metrics dictionary\n",
    "            metrics['DEL'] += res[0]\n",
    "            metrics['INS'] += res[1]\n",
    "            metrics['NDCG'] += res[2]\n",
    "            metrics['POS_at_5'] += res[3]\n",
    "            metrics['POS_at_10'] += res[4]\n",
    "            metrics['POS_at_20'] += res[5]\n",
    "            metrics['NEG_at_5'] += res[6]\n",
    "            metrics['NEG_at_10'] += res[7]\n",
    "            metrics['NEG_at_20'] += res[8]\n",
    "\n",
    "    a = test_array.shape[0]\n",
    "\n",
    "    # Print all metrics\n",
    "    for metric_name, values in metrics.items():\n",
    "        print(f'{metric_name}_{expl_name}: ', np.mean(values)/a)\n",
    "\n",
    "    # Return normalized metrics\n",
    "    return {metric_name: values/a for metric_name, values in metrics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04fcdd0a-259c-411b-bc56-ac0c6e10dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_baselines(data_name, recommender_name):\n",
    "    global num_users, num_items, device, kw_dict, recommender, test_array, test_data, items_array, jaccard_dict, cosine_dict, pop_dict, item_to_cluster, shap_values\n",
    "\n",
    "    # Update global variables for the current dataset and recommender\n",
    "    num_users = num_users_dict[data_name]\n",
    "    num_items = num_items_dict[data_name]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load dataset-specific files\n",
    "    DP_DIR = Path(\"processed_data\", data_name)\n",
    "    files_path = Path(export_dir.parent, DP_DIR)\n",
    "    test_data = pd.read_csv(Path(files_path, f'test_data_{data_name}.csv'), index_col=0)\n",
    "    test_array = test_data.to_numpy()\n",
    "    items_array = np.eye(num_items)\n",
    "\n",
    "    with open(Path(files_path, f'jaccard_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "        jaccard_dict = pickle.load(f)\n",
    "    with open(Path(files_path, f'cosine_based_sim_{data_name}.pkl'), 'rb') as f:\n",
    "        cosine_dict = pickle.load(f)\n",
    "    with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "        pop_dict = pickle.load(f)\n",
    "    with open(Path(files_path, f'item_to_cluster_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "        item_to_cluster = pickle.load(f)\n",
    "    with open(Path(files_path, f'shap_values_{recommender_name}_{data_name}.pkl'), 'rb') as f:\n",
    "        shap_values = pickle.load(f)\n",
    "\n",
    "    # Update kw_dict\n",
    "    kw_dict = {\n",
    "        'device': device,\n",
    "        'num_items': num_items,\n",
    "        'num_features': num_items,\n",
    "        'demographic': False,\n",
    "        'pop_array': np.array([pop_dict.get(i, 0) for i in range(num_items)]),\n",
    "        'all_items_tensor': torch.eye(num_items).to(device),\n",
    "        'static_test_data': test_data,\n",
    "        'items_array': items_array,\n",
    "        'output_type': output_type_dict[recommender_name],\n",
    "        'recommender_name': recommender_name,\n",
    "        'files_path': files_path\n",
    "    }\n",
    "\n",
    "    # Load recommender\n",
    "    recommender = load_recommender()\n",
    "    \n",
    "    # Generate explanation dictionaries if they don't exist\n",
    "    create_dictionaries = False  # Set to False if dictionaries already exist\n",
    "    if create_dictionaries:\n",
    "        recommender.eval()\n",
    "        \n",
    "        # Initialize dictionaries\n",
    "        jaccard_expl_dict = {}\n",
    "        cosine_expl_dict = {}\n",
    "        lime_expl_dict = {}\n",
    "        accent_expl_dict = {}\n",
    "        shap_expl_dict = {}\n",
    "        \n",
    "        print(f\"Generating explanation dictionaries for {data_name} {recommender_name}...\")\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(test_array.shape[0])):\n",
    "                user_vector = test_array[i]\n",
    "                user_tensor = torch.FloatTensor(user_vector).to(device)\n",
    "                user_id = int(test_data.index[i])\n",
    "\n",
    "                item_id = int(get_user_recommended_item(user_tensor, recommender, **kw_dict).detach().cpu().numpy())\n",
    "                item_vector = items_array[item_id]\n",
    "                item_tensor = torch.FloatTensor(item_vector).to(device)\n",
    "\n",
    "                user_vector[item_id] = 0\n",
    "                user_tensor[item_id] = 0\n",
    "\n",
    "                recommender.to(device)\n",
    "\n",
    "                jaccard_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type='jaccard')\n",
    "                cosine_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type='cosine')\n",
    "                lime_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type='lime')\n",
    "                accent_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type='accent')\n",
    "                shap_expl_dict[user_id] = single_user_expl(user_vector, user_tensor, item_id, item_tensor, num_items, recommender, mask_type='shap', user_id=user_id)\n",
    "\n",
    "        # Save dictionaries\n",
    "        for name, dict_obj in [\n",
    "            ('jaccard', jaccard_expl_dict),\n",
    "            ('cosine', cosine_expl_dict),\n",
    "            ('lime', lime_expl_dict),\n",
    "            ('accent', accent_expl_dict),\n",
    "            ('shap', shap_expl_dict)\n",
    "        ]:\n",
    "            with open(Path(files_path, f'{recommender_name}_{name}_expl_dict.pkl'), 'wb') as handle:\n",
    "                pickle.dump(dict_obj, handle)\n",
    "        \n",
    "        print(\"Dictionaries generated and saved.\")\n",
    "\n",
    "    # Run all baselines\n",
    "    baselines = ['jaccard', 'cosine', 'lime', 'lxr', 'accent', 'shap']\n",
    "    results = {}\n",
    "\n",
    "    for baseline in baselines:\n",
    "        print(f\"Running {baseline} baseline for {data_name} {recommender_name}\")\n",
    "        results[baseline] = eval_one_expl_type(baseline)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee87b2df-9d64-48c0-b233-c9553760ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics(results, data_name, recommender_name):\n",
    "    # Mapping of metrics to their display properties\n",
    "    metrics_mapping = {\n",
    "        'DEL':      ('AUC DEL-P@K', 'DEL-P@K', 'Lower is better'),\n",
    "        'INS':      ('AUC INS-P@K', 'INS-P@K', 'Higher is better'),\n",
    "        'NDCG':     ('AUC NDCG-P',  'NDCG-P',  'Lower is better'),\n",
    "        'POS_at_5': ('AUC POS-P@5', 'POS-P@5', 'Lower is better'),\n",
    "        'POS_at_10':('AUC POS-P@10','POS-P@10','Lower is better'),\n",
    "        'POS_at_20':('AUC POS-P@20','POS-P@20','Lower is better'),\n",
    "        'NEG_at_5': ('AUC NEG-P@5', 'NEG-P@5', 'Higher is better'),\n",
    "        'NEG_at_10':('AUC NEG-P@10','NEG-P@10','Higher is better'),\n",
    "        'NEG_at_20':('AUC NEG-P@20','NEG-P@20','Higher is better')\n",
    "    }\n",
    "    \n",
    "    # Styling\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    markers = ['o', 's', '^', 'D', 'v', 'x']\n",
    "    linestyles = ['-', '--', '-.', ':', (0, (3, 1, 1, 1)), (0, (5, 2))]\n",
    "    \n",
    "    # Create plots directory\n",
    "    os.makedirs('plots', exist_ok=True)\n",
    "    \n",
    "    # Plot each metric\n",
    "    for metric_name, (title_name, y_label, indicator) in metrics_mapping.items():\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Plot each baseline\n",
    "        legend_labels = []\n",
    "        for i, (baseline, baseline_metrics) in enumerate(results.items()):\n",
    "            if metric_name not in baseline_metrics:\n",
    "                print(f\"Warning: {metric_name} not found in {baseline} metrics\")\n",
    "                continue\n",
    "                \n",
    "            values = baseline_metrics[metric_name]\n",
    "            x = np.linspace(0, 1, len(values))\n",
    "            \n",
    "            plt.plot(\n",
    "                x, values,\n",
    "                color=colors[i % len(colors)],\n",
    "                linestyle=linestyles[i % len(linestyles)],\n",
    "                marker=markers[i % len(markers)],\n",
    "                markersize=8,\n",
    "                linewidth=2,\n",
    "                markevery=0.1,\n",
    "                label=baseline.upper()\n",
    "            )\n",
    "            legend_labels.append(baseline.upper())\n",
    "        \n",
    "        plt.xlabel(\"Masked Items Percentage\", fontsize=30)\n",
    "        plt.ylabel(y_label, fontsize=30)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7, linewidth=0.5)\n",
    "        plt.xticks(fontsize=18)\n",
    "        plt.yticks(fontsize=18)\n",
    "        \n",
    "        # Add legend if we have labels\n",
    "        if legend_labels:\n",
    "            plt.legend(fontsize=14, loc='best')\n",
    "        \n",
    "        # Save plot\n",
    "        safe_display_name = title_name.replace(\" \", \"_\").replace(\"@\", \"at\")\n",
    "        plot_path = f'plots/{safe_display_name}_{data_name}_{recommender_name}.pdf'\n",
    "        plt.savefig(plot_path, format='pdf', bbox_inches='tight')\n",
    "        print(f\"Saved plot to {plot_path}\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d41114e-a2f1-45ab-9782-dc2a3dc71235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recommender(data_name, recommender_name):\n",
    "    DP_DIR = Path(\"processed_data\", data_name)\n",
    "    files_path = Path(\"/storage/mikhail/PI4Rec\", DP_DIR)\n",
    "    \n",
    "    num_users = num_users_dict[data_name]\n",
    "    num_items = num_items_dict[data_name]\n",
    "    num_features = num_items_dict[data_name]\n",
    "    \n",
    "    with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "        pop_dict = pickle.load(f)\n",
    "    pop_array = np.zeros(len(pop_dict))\n",
    "    for key, value in pop_dict.items():\n",
    "        pop_array[key] = value\n",
    "\n",
    "    test_data = pd.read_csv(Path(files_path,f'test_data_{data_name}.csv'), index_col=0)\n",
    "    static_test_data = pd.read_csv(Path(files_path,f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "    \n",
    "    test_array = static_test_data.iloc[:,:-2].to_numpy()\n",
    "    items_array = np.eye(num_items)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    all_items_tensor = torch.Tensor(items_array).to(device)\n",
    "\n",
    "    output_type = output_type_dict[recommender_name]\n",
    "    hidden_dim = hidden_dim_dict[(data_name,recommender_name)]\n",
    "    recommender_path = recommender_path_dict[(data_name,recommender_name)]\n",
    "\n",
    "    kw_dict = {\n",
    "        'device': device,\n",
    "        'num_items': num_items,\n",
    "        'demographic': False,\n",
    "        'num_features': num_features,\n",
    "        'pop_array': pop_array,\n",
    "        'all_items_tensor': all_items_tensor,\n",
    "        'static_test_data': static_test_data,\n",
    "        'items_array': items_array,\n",
    "        'output_type': output_type,\n",
    "        'recommender_name': recommender_name,\n",
    "        'files_path': files_path\n",
    "    }\n",
    "\n",
    "    recommender = load_recommender()\n",
    "\n",
    "    print(f\"Processing {data_name} dataset with {recommender_name} recommender\")\n",
    "    \n",
    "    results = {}\n",
    "    for expl_name in ['pop', 'jaccard', 'cosine', 'lime', 'lxr', 'accent', 'shap']:\n",
    "        results[expl_name] = eval_one_expl_type(expl_name, data_name, recommender_name, test_array, test_data, items_array, recommender, kw_dict)\n",
    "    \n",
    "    if results:  # Check if results is not empty\n",
    "        print(f\"Got results for {data_name} {recommender_name}\")\n",
    "        print(f\"Available metrics: {list(results.items())[0][1].keys()}\")\n",
    "        plot_all_metrics(results, data_name, recommender_name)\n",
    "    else:\n",
    "        print(f\"No results generated for {data_name} {recommender_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b97d008a-787f-4e42-8999-1ce760cdf119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "\n",
    "def save_results_to_excel(results, filename):\n",
    "    wb = Workbook()\n",
    "    \n",
    "    # Create MF recommender sheet\n",
    "    ws_mf = wb.active\n",
    "    ws_mf.title = \"MF Recommender\"\n",
    "    \n",
    "    # Create VAE recommender sheet\n",
    "    ws_vae = wb.create_sheet(title=\"VAE Recommender\")\n",
    "    \n",
    "    for ws, title in [(ws_mf, \"AUC values for explaining an MF recommender.\"), \n",
    "                      (ws_vae, \"AUC values for explaining a VAE recommender.\")]:\n",
    "        \n",
    "        # Add title\n",
    "        ws['A1'] = f\"Table: {title}\"\n",
    "        ws['A1'].font = Font(bold=True)\n",
    "        ws.merge_cells('A1:G1')\n",
    "        \n",
    "        # Add headers\n",
    "        headers = ['Method', 'k=5', 'k=10', 'k=20', 'DEL', 'INS', 'NDCG']\n",
    "        for col, header in enumerate(headers, start=1):\n",
    "            ws.cell(row=3, column=col, value=header).font = Font(bold=True)\n",
    "        \n",
    "        # Add data\n",
    "        for row, (method, values) in enumerate(results.items(), start=4):\n",
    "            ws.cell(row=row, column=1, value=method)\n",
    "            for col, value in enumerate(values, start=2):\n",
    "                ws.cell(row=row, column=col, value=value)\n",
    "    \n",
    "    # Apply some styling\n",
    "    for ws in [ws_mf, ws_vae]:\n",
    "        for row in ws[f'A3:G{ws.max_row}']:\n",
    "            for cell in row:\n",
    "                cell.border = Border(left=Side(style='thin'), \n",
    "                                     right=Side(style='thin'), \n",
    "                                     top=Side(style='thin'), \n",
    "                                     bottom=Side(style='thin'))\n",
    "    \n",
    "    wb.save(filename)\n",
    "\n",
    "def run_and_format_results(data_name, recommender_name):\n",
    "    results = {}\n",
    "    for expl_name in ['jaccard', 'cosine', 'lime', 'shap', 'accent', 'lxr']:\n",
    "        raw_results = eval_one_expl_type(expl_name)\n",
    "        \n",
    "        # Extract POS values\n",
    "        pos_at_5 = raw_results['POS_at_5'][-1]  # Last value represents 100% of items\n",
    "        pos_at_10 = raw_results['POS_at_10'][-1]\n",
    "        pos_at_20 = raw_results['POS_at_20'][-1]\n",
    "        \n",
    "        # Format results as per the desired output\n",
    "        results[expl_name.upper()] = [\n",
    "            pos_at_5,\n",
    "            pos_at_10,\n",
    "            pos_at_20,\n",
    "            raw_results['DEL'][-1],\n",
    "            raw_results['INS'][-1],\n",
    "            raw_results['NDCG'][-1]\n",
    "        ]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7746ce8-194f-48a4-beb7-ce81c6681249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a11be6e8-ba23-4189-a90b-219e9f634b73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing ML1M dataset with MLP recommender\n",
      "==================================================\n",
      "Running jaccard baseline for ML1M MLP\n",
      " ============ Start explaining ML1M MLP by jaccard ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1208 [00:00<?, ?it/s]/storage/mikhail/PI4Rec/code/recommenders_architecture.ipynb:42: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3725.)\n",
      "  \"import logging\"\n",
      "100%|██████████| 1208/1208 [03:05<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEL_jaccard:  0.7930111541019019\n",
      "INS_jaccard:  0.9080472112790845\n",
      "NDCG_jaccard:  0.6539703827970345\n",
      "POS_at_5_jaccard:  0.7167369054786273\n",
      "POS_at_10_jaccard:  0.7735550872968092\n",
      "POS_at_20_jaccard:  0.8068181818181818\n",
      "NEG_at_5_jaccard:  0.9064569536423841\n",
      "NEG_at_10_jaccard:  0.9422034918723661\n",
      "NEG_at_20_jaccard:  0.9591360626128839\n",
      "Running cosine baseline for ML1M MLP\n",
      " ============ Start explaining ML1M MLP by cosine ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [03:32<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEL_cosine:  0.775549896761866\n",
      "INS_cosine:  0.9109799832905053\n",
      "NDCG_cosine:  0.5886977704899012\n",
      "POS_at_5_cosine:  0.6457706201083685\n",
      "POS_at_10_cosine:  0.7031908488862132\n",
      "POS_at_20_cosine:  0.7436032510535822\n",
      "NEG_at_5_cosine:  0.9132299819385913\n",
      "NEG_at_10_cosine:  0.9441601444912703\n",
      "NEG_at_20_cosine:  0.9621462974111981\n",
      "Running lime baseline for ML1M MLP\n",
      " ============ Start explaining ML1M MLP by lime ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [02:44<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEL_lime:  0.7347956507691433\n",
      "INS_lime:  0.927924835313199\n",
      "NDCG_lime:  0.5756367655607778\n",
      "POS_at_5_lime:  0.6438892233594221\n",
      "POS_at_10_lime:  0.7251655629139073\n",
      "POS_at_20_lime:  0.7775436484045756\n",
      "NEG_at_5_lime:  0.9597381095725466\n",
      "NEG_at_10_lime:  0.9724563515954244\n",
      "NEG_at_20_lime:  0.9766706803130644\n",
      "Running lxr baseline for ML1M MLP\n",
      " ============ Start explaining ML1M MLP by lxr ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [02:47<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEL_lxr:  0.5925845288553352\n",
      "INS_lxr:  0.9361609041260208\n",
      "NDCG_lxr:  0.44235416681464806\n",
      "POS_at_5_lxr:  0.4571794099939795\n",
      "POS_at_10_lxr:  0.5209211318482841\n",
      "POS_at_20_lxr:  0.5705900060204696\n",
      "NEG_at_5_lxr:  0.9379139072847682\n",
      "NEG_at_10_lxr:  0.9621462974111981\n",
      "NEG_at_20_lxr:  0.9707254665863938\n",
      "Running accent baseline for ML1M MLP\n",
      " ============ Start explaining ML1M MLP by accent ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [02:44<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEL_accent:  0.7290242289075612\n",
      "INS_accent:  0.9104173811102325\n",
      "NDCG_accent:  0.6522920093780035\n",
      "POS_at_5_accent:  0.7072546658639374\n",
      "POS_at_10_accent:  0.7595574954846478\n",
      "POS_at_20_accent:  0.7966586393738712\n",
      "NEG_at_5_accent:  0.7839403973509934\n",
      "NEG_at_10_accent:  0.8594220349187237\n",
      "NEG_at_20_accent:  0.8933624322697171\n",
      "Running shap baseline for ML1M MLP\n",
      " ============ Start explaining ML1M MLP by shap ============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1208/1208 [02:45<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEL_shap:  0.8620954945393386\n",
      "INS_shap:  0.8497019496877846\n",
      "NDCG_shap:  0.764594112289649\n",
      "POS_at_5_shap:  0.8503913305237808\n",
      "POS_at_10_shap:  0.8969747140276941\n",
      "POS_at_20_shap:  0.9214328717639976\n",
      "NEG_at_5_shap:  0.8169777242624925\n",
      "NEG_at_10_shap:  0.8556592414208309\n",
      "NEG_at_20_shap:  0.8816225165562914\n",
      "Saved plot to plots/AUC_DEL-PatK_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_INS-PatK_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NDCG-P_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_POS-Pat5_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_POS-Pat10_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_POS-Pat20_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NEG-Pat5_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NEG-Pat10_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NEG-Pat20_ML1M_MLP.pdf\n",
      "\n",
      "All evaluations completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Define datasets and recommenders\n",
    "data_names = [\"ML1M\"]#, \"Yahoo\", \"Pinterest\"\n",
    "recommender_names = [\"MLP\"]#, \"VAE\", \"NCF\"\n",
    "\n",
    "# Create a mapping between explainer names and actual explainer functions\n",
    "explainer_mapping = {\n",
    "    'jaccard': find_jaccard_mask,\n",
    "    'cosine': find_cosine_mask,\n",
    "    'lime': find_lime_mask,\n",
    "    'lxr': find_lxr_mask,\n",
    "    'accent': find_accent_mask,\n",
    "    'shap': find_shapley_mask\n",
    "}\n",
    "\n",
    "# Store all results\n",
    "all_results = {}\n",
    "\n",
    "for data_name in data_names:\n",
    "    # Setup paths and load data\n",
    "    DP_DIR = Path(\"processed_data\", data_name)\n",
    "    files_path = Path(\"/storage/mikhail/PI4Rec\", DP_DIR)\n",
    "    \n",
    "    # Get dataset dimensions\n",
    "    num_users = num_users_dict[data_name] \n",
    "    num_items = num_items_dict[data_name] \n",
    "    num_features = num_items_dict[data_name]\n",
    "        \n",
    "    # Load popularity data\n",
    "    with open(Path(files_path, f'pop_dict_{data_name}.pkl'), 'rb') as f:\n",
    "        pop_dict = pickle.load(f)\n",
    "    pop_array = np.zeros(len(pop_dict))\n",
    "    for key, value in pop_dict.items():\n",
    "        pop_array[key] = value\n",
    "\n",
    "    # Load training and test data\n",
    "    train_data = pd.read_csv(Path(files_path, f'train_data_{data_name}.csv'), index_col=0)\n",
    "    test_data = pd.read_csv(Path(files_path, f'test_data_{data_name}.csv'), index_col=0)\n",
    "    static_test_data = pd.read_csv(Path(files_path, f'static_test_data_{data_name}.csv'), index_col=0)\n",
    "    \n",
    "    # Convert to arrays\n",
    "    train_array = train_data.to_numpy()\n",
    "    test_array = static_test_data.iloc[:,:-2].to_numpy()\n",
    "    items_array = np.eye(num_items)\n",
    "    all_items_tensor = torch.Tensor(items_array).to(device)\n",
    "\n",
    "    for recommender_name in recommender_names:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing {data_name} dataset with {recommender_name} recommender\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Setup recommender configuration\n",
    "        output_type = output_type_dict[recommender_name]\n",
    "        hidden_dim = hidden_dim_dict[(data_name, recommender_name)]\n",
    "        recommender_path = recommender_path_dict[(data_name, recommender_name)]\n",
    "\n",
    "        # Update kw_dict for current configuration\n",
    "        kw_dict = {\n",
    "            'device': device,\n",
    "            'num_items': num_items,\n",
    "            'demographic': False,\n",
    "            'num_features': num_features,\n",
    "            'pop_array': pop_array,\n",
    "            'all_items_tensor': all_items_tensor,\n",
    "            'static_test_data': static_test_data,\n",
    "            'items_array': items_array,\n",
    "            'output_type': output_type,\n",
    "            'recommender_name': recommender_name,\n",
    "            'files_path': files_path\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Run baselines and get results\n",
    "            results = {}\n",
    "            for baseline in ['jaccard', 'cosine', 'lime', 'lxr', 'accent', 'shap']:\n",
    "                print(f\"Running {baseline} baseline for {data_name} {recommender_name}\")\n",
    "                results[baseline] = eval_one_expl_type(baseline)\n",
    "            \n",
    "            all_results[(data_name, recommender_name)] = results\n",
    "            \n",
    "            # Generate and save visualizations for current combination\n",
    "            plot_all_metrics(results, data_name, recommender_name)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {data_name}-{recommender_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "print(\"\\nAll evaluations completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe4f9310-964a-4ce5-b4ae-046279e30d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to plots/AUC_DEL-PatK_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_INS-PatK_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NDCG-P_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_POS-Pat5_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_POS-Pat10_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_POS-Pat20_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NEG-Pat5_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NEG-Pat10_ML1M_MLP.pdf\n",
      "Saved plot to plots/AUC_NEG-Pat20_ML1M_MLP.pdf\n"
     ]
    }
   ],
   "source": [
    "plot_all_metrics(results, data_name, recommender_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5c0b4f-e22a-4544-b38a-69b5639d4ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219789d9-5fa4-4fc4-b4c7-2999c99616e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1976c-7bbf-48d0-8545-322c1d85d599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4401d52d-d3d1-49fe-85b7-5eea74e2a03a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
